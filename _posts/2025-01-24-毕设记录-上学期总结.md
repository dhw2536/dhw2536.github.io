---
layout:     post
title:      毕设记录-上学期总结
subtitle:   本研究围绕集群机器人在编队作业场景下的协同路径规划展开，设计了基于麦克纳姆轮的全向移动机器人平台，开发了通信、建图和导航模块，并结合领航-跟随算法与深度强化学习算法，提升机器人在复杂环境中的协同作业能力。
date:       2025-01-24
author:     Space
header-img: img/the-first.png
catalog:   true
tags:
    - 本科毕设探索

---





# 编队作业场景下集群机器人协同路径规划研究



## 毕业设计任务书

#### **一、学生姓名：**段宏伟       **学号：**U202141170

#### **二、题目：**编队作业场景下集群机器人协同路径规划研究

#### **三、题目来源：**真实  √  自拟  □ 

#### **四、结业方式：**论文  √  设计  □

#### **五、主要内容：**

1. **集群机器人微缩平台的设计与实现：** 设计并构建基于麦克纳姆轮的全向移动机器人，集成激光雷达、深度相机、IMU等多种传感器，实现高精度的环境感知和定位功能，为后续算法研究提供硬件基础。
2. **机器人集群通信、建图和导航模块的开发：** 基于ROS平台，开发机器人集群的通信框架，实现跨平台的多机通信与协同工作；构建共享地图，支持集群机器人的协同建图与导航功能，提升整体环境感知与路径规划能力。
3. **领航-跟随算法的研究与实现：** 研究领航-跟随算法的原理，解决机器人之间的通信、定位和协同控制问题；开发稳定的队形控制算法，实现集群机器人在复杂环境中的有序编队运动，增强协同作业能力。
4. **路径规划算法的部署与创新：** 在实车平台上部署传统路径规划算法（如A*算法），评估其在实际应用中的性能；提出基于深度强化学习算法的路径规划方法，提高路径规划的效率和适应性，提升机器人在动态环境中的自主导航能力。
5. **算法的仿真与实物验证：** 利用Gazebo仿真平台和实际机器人平台，对领航-跟随、队形控制、路径规划算法进行全面的仿真与实验验证，评估算法的有效性和鲁棒性，为算法的实际应用提供支持。



#### **六、主要（技术）要求：**

1. **掌握关键技术：** 熟练掌握ROS系统的使用，熟悉Python和C++编程语言；深入理解深度强化学习和Transformer模型在路径规划中的应用，能够将其有效地融合到机器人路径规划算法中。
2. **基于ROS的多机器人通信框架：** 熟悉ROS多机通信机制，能够构建稳定高效的多机器人通信框架，实现机器人之间的数据共享与协同工作。
3. **熟悉多种传感器的集成与使用：** 熟练使用激光雷达、深度相机、IMU等传感器，具备传感器数据处理和融合的能力，实现高精度的环境感知和自主定位。
4. **领航-跟随算法的研究与实现：** 研究领航-跟随算法的原理，解决机器人之间的通信、定位和协同控制问题；开发队形控制算法，实现集群机器人稳定的编队运动，提高集群机器人在复杂环境下的协同能力。
5. **开发并优化路径规划算法：** 掌握传统路径规划算法的原理与实现，能够在实际应用中进行有效部署；能够结合深度强化学习方法，开发高效的路径规划算法，适应复杂动态环境下的机器人导航需求。



#### **七、日程安排：**

- **第1-2周**：
  -  查阅国内外相关文献，了解集群机器人协同控制和路径规划的研究现状
  - 明确研究目标，制定详细的研究方案和技术路线
- **第3-4周**：
  - 设计并搭建基于麦克纳姆轮的全向移动机器人平台，集成激光雷达、深度相机、IMU等传感器
  - 完成多机器人集群微缩平台的搭建与初步调试，确保硬件平台的稳定性和可用性。
  - 开展开题报告，详细阐述研究背景和目标。
- **第5-6周**：
  - 开发单机器人系统的ROS程序，实现基本的运动控制和传感器数据读取
  - 实现单机器人自主定位和建图功能
- **第7-8周**：
  - 开发多机器人通信模块，实现ROS跨平台多机通信
  - 研究并实现领航-跟随算法，实现基本的队形控制
- **第9-10周**：
  - 研究传统路径规划算法（如A*算法），并在机器人平台上实现
  - 研究并学习深度强化学习相关内容，并阅读相关文献了解其在路径规划中的应用
  - 搭建Gazebo仿真环境，进行路径规划算法的仿真测试
- **第11-12周**：
  - 开发基于深度强化学习的路径规划算法，优化机器人导航性能
  - 在仿真和实际环境中测试和验证所提出的算法
  - 分析实验结果，评估算法的有效性和鲁棒性
- **第13周**：
  - 修改并整理毕业设计论文，整理《毕业设计报告书》。
  - 完成论文的初稿和定稿。
- **第14周**：
  - 完成毕业论文查重工作，确保论文符合学术规范。
- **第15周**：
  - 准备答辩PPT并进行答辩演练，完成毕业论文答辩。



#### **八、主要参考文献和书目：**

1. Quigley, M., et al. (2009). "ROS: an open-source Robot Operating System." ICRA workshop on open source software. Vol. 3. No. 3.2.
2. Koenig, N., & Howard, A. (2004). "Design and use paradigms for Gazebo, an open-source multi-robot simulator." 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). Vol. 3. IEEE.
3. Sutton, R. S., & Barto, A. G. (2018). "Reinforcement Learning: An Introduction." MIT Press.
4. LaValle, S. M. (2006). "Planning Algorithms." Cambridge University Press.
5. Silver, D., et al. (2016). "Mastering the game of Go with deep neural networks and tree search." Nature 529, 484–489.
6. Kober, J., Bagnell, J. A., & Peters, J. (2013). "Reinforcement learning in robotics: A survey." The International Journal of Robotics Research 32(11), 1238-1274.
7. Thrun, S., Burgard, W., & Fox, D. (2005). "Probabilistic Robotics." MIT Press.



## 学期工作计划

#### **段宏伟2024-2025学年春季学期工作计划**

参考下面内容完成工作计划即可



#### 1.潘登辉

![image-20250123105744715](https://raw.githubusercontent.com/dhw2536/Picture/main/202501232208601.png)

#### 2.木崇章

![image-20250123105823851](https://raw.githubusercontent.com/dhw2536/Picture/main/202501232208602.png)



## 毕设开题报告大纲

### 1 课题背景及研究意义

#### 1.1 研究背景

- **政策与市场背景**
  智能物流和仓储自动化的发展得到了国家政策的大力支持，尤其是《智能制造发展规划（2016-2020年）》明确推动智能机器人的广泛应用。同时，机器人搬运系统的市场份额持续增长，多机器人协同作业需求不断提升，传统单一机器人和大型搬运设备的局限性促使多机器人协同解决方案成为趋势。
- **集群机器人编队概述**
  集群机器人编队指多个机器人通过协同合作完成任务，具有任务执行效率高、资源利用优化等优势。在物流领域，集群机器人编队可大幅提升货物搬运和分拣效率，降低运营成本。领航-跟随法作为一种重要的协同控制策略，能够确保编队的稳定性和动态适应性。
- **现有研究问题**
  尽管多机器人系统在路径规划和协同控制方面取得了一定进展，但仍面临路径冲突、通信延迟和环境不确定性等挑战。领航-跟随法结合深度强化学习的路径规划方法展现出应对这些挑战的潜力。

#### 1.2 国内外研究现状.

#### 1.3 研究意义



## 2. 设计内容与计划

#### **集群机器人微缩平台设计与实现**

设计并搭建基于麦克纳姆轮的全向移动机器人，配备激光雷达、深度相机等传感器，实现高精度的环境感知和定位。

#### **集群系统功能模块开发**

开发机器人集群的通信、建图和导航模块，实现跨平台的ROS多机通信和协同工作。

#### **领航-跟随与队形控制算法研究**

研究领航-跟随算法在集群机器人系统中的实现方法，解决机器人之间的通信、定位和协同控制问题。

#### **路径规划算法研究**

结合传统路径规划方法（如A*算法）和深度强化学习算法，优化领航者的路径规划，使其能够带领其他机器人保持编队形式。

#### **实验验证**

在Gazebo仿真环境和实际环境中验证领航-跟随、队形控制和协同路径规划算法的有效性。



#### 参考文献 









## 毕设提纲及思路

**中文题目：**编队作业场景下集群机器人协同路径规划研究

**英文题目**：Research on Cooperative Path Planning of Cluster Robots in Formation Tasks



### 摘要

- 本研究聚焦于智能物流场景下集群机器人协同控制与路径规划问题。
- 设计并实现了一套基于麦克纳姆轮的全向移动机器人微缩平台，配备激光雷达、深度相机等多种传感器，支持高精度的环境感知与定位。
- 开发了机器人集群的通信、建图和导航模块，实现了跨平台的ROS多机通信和协同工作。
- 深入研究了领航-跟随算法及其在集群机器人系统中的应用，开发了队形控制算法，实现了机器人的协同运动。
- 结合传统路径规划算法和深度强化学习算法，提出了一种基于Transformer模型的路径规划方法，显著提高了机器人在复杂动态环境中的自主导航能力。
- 最后，通过Gazebo仿真和实车验证，证明了所提算法的有效性和鲁棒性。
- 本研究为智能物流领域中的集群机器人协同作业提供了新的技术思路和解决方案，具有重要的理论意义和应用价值。

背景需求

本研究针对……问题，基于……技术，提出……算法，旨在提高……水平。

构建了……模型，涵盖了……。其中……技术/模型包括……内容/方法，并分析了……，使用了……。

设计了……内容/实验。分析了……，研究了……步骤和原理，基于……进行实验与分析。

……

……



### 关键词

集群机器人；编队作业；路径规划；领航跟随；深度强化学习



### 1. 课题背景及研究意义

#### **1.1 研究背景**

##### **1.1.1 政策与市场背景**

- **国家政策支持**：智能物流和仓储自动化的发展得到了国家政策的大力支持。特别是《智能制造发展规划（2016-2020年）》明确指出，政府致力于推动智能机器人的广泛应用。这些政策为智能机器人在各行业的应用创造了良好的环境，促进了技术创新，满足了自动化解决方案日益增长的需求。
- **市场需求分析：**
  机器人搬运系统的市场份额持续增长，多机器人协同作业的需求亦在不断提升。这一趋势的具体原因包括：
  - **单一机器人面临的挑战：** 单独使用机器人完成复杂任务时，常常效率较低，难以应对多样化的作业需求。
  - **大型搬运机械的成本低效：** 采购和维护大型、高价的搬运设备成本较高，性价比不佳。
  - **多机器人协同的优势：** 部署多台机器人协同工作是一种更具成本效益的解决方案。例如，若干机器人以三角形编队共同搬运大型物品，不仅提高了任务的执行效率，还增强了作业的灵活性和适应性。

##### **1.1.2 集群机器人编队概述**

**概念与优势：**
集群机器人编队指的是多个机器人协调合作，共同完成既定任务的工作模式。这种编队方式具有多方面的优势：

- **任务执行效率提升：** 通过协同合作，任务的完成速度和效率显著提高。
- **资源优化利用：** 多机器人协同能够有效减少时间和资源的浪费，充分发挥各机器人的优势。

**应用价值：**
在物流领域，集群机器人编队可大幅提升货物搬运和分拣的效率。优化后的物流过程不仅加快了作业速度，还降低了运营成本，实现了流程的整体优化。

**协同控制：**
集群机器人编队的核心在于协同控制策略的实施。其中，领航跟随法是一种重要的协同控制方法。该方法通过指定一台领航机器人指导编队，其余跟随机器人根据领航机器人的指引保持相对位置。这种控制策略不仅确保了编队的稳定性，还能够根据环境变化动态调整编队形态，提升集群机器人在实际物流作业中的应用效果和价值。

##### **1.1.3 现有研究问题**

**当前挑战：**
尽管多机器人系统在路径规划和协同控制方面取得了一定进展，但仍面临诸多挑战：

- **路径冲突：** 保证多机器人在移动过程中不发生碰撞或路径交叉是一个关键问题。
- **通信延迟：** 通信系统中的延迟可能影响实时协调和决策的效率。
- **环境不确定性：** 动态和不可预测的环境增加了多机器人系统在协同和导航中的复杂性。

**研究优势：**
领航跟随法结合深度强化学习的路径规划方法，展现出应对上述挑战的潜力。具体优势包括：

- **编队稳定性：** 即使在动态环境中，仍能保持稳定的编队形式。
- **自适应路径规划：** 通过深度强化学习，机器人能够在复杂环境中进行有效导航。
- **冲突解决能力：** 有效减少路径冲突，适应通信延迟，确保多机器人协同工作的稳健性。

通过克服这些挑战，本研究旨在提升多机器人系统的自主导航和协同控制能力，从而提高智能物流作业的整体效率和实用性。



#### **1.2 国内外研究现状**

##### **1.2.1 集群机器人研究进展**

**1.2.1.1 国内研究现状**

近年来，国内在集群机器人领域取得了显著的发展。研究机构和高校积极开展相关科研项目，涌现出一系列具有代表性的研究成果。例如，北京大学的某研究团队在集群机器人协同控制方面取得了突破性进展，开发出高效的协同算法，并在实际应用中展示了其优越的性能。此外，国内多项国家重点研发计划也涵盖了集群机器人技术的发展，通过资金和政策的支持，推动了该领域的快速进步。然而，尽管取得了一定成果，国内在集群机器人的智能化程度和系统集成能力方面仍需进一步提升，以缩小与国际先进水平的差距。

**1.2.1.2 国外研究现状**

国外在集群机器人领域的研究起步较早，技术体系相对完善。欧美及日本等发达国家的研究机构和企业在集群机器人协同控制、路径规划及自主决策等方面处于领先地位。例如，麻省理工学院（MIT）开发的集群机器人系统在复杂环境中的协同作业能力表现出色，采用了先进的分布式控制算法，显著提高了系统的鲁棒性和效率。同时，国外的研究在算法优化、硬件集成及实际应用场景测试方面也取得了诸多成果。然而，国际研究也存在一定的局限性，如高成本、技术复杂性以及在特定应用场景中的适应性问题，这些因素在一定程度上限制了集群机器人技术的广泛推广与应用。

##### **1.2.2 机器人协同工作研究进展**

编队控制作为机器人协同工作的核心技术之一，其研究进展备受关注。近年来，诸如领航跟随法等协同控制算法得到了广泛研究，并在多机器人系统中显示出良好的应用前景。当前的研究主要集中在提高编队的稳定性、灵活性以及对动态环境的适应能力。例如，某些最新研究成果通过引入深度学习技术，增强了机器人对环境变化的感知和响应能力，从而实现了更为高效和智能的协同作业。此外，协同控制中的优化算法也在不断进化，以解决多机器人系统中的通信延迟、信息共享以及任务分配等关键问题，进一步提升了集群机器人的整体性能。

##### **1.2.3 集群机器人路径规划研究进展**

**1.2.3.1 传统路径规划算法**

传统路径规划算法如Dijkstra算法和A\*算法在集群机器人领域中得到了广泛应用。这些算法通过构建代价图和启发式搜索方法，实现了较为高效的路径计算。然而，传统算法在应对复杂环境和动态障碍物时，表现出一定的局限性。例如，Dijkstra算法虽然能够保证找到最短路径，但其计算复杂度较高，难以适应大规模集群机器人的实时路径规划需求。而A*算法通过引入启发式函数在一定程度上优化了搜索效率，但在高维空间和动态环境中的表现仍需进一步改进。因此，尽管传统路径规划算法在集群机器人路径规划中具有重要的基础价值，但其在智能化和实时性方面亟待提升。

**1.2.3.2 深度强化学习算法**

随着人工智能技术的发展，深度强化学习算法在集群机器人路径规划中展现出强大的潜力。以GoT-GTRL（具体算法名称待定）为代表的深度强化学习方法，通过结合深度神经网络和强化学习框架，实现了机器人在复杂环境下的自主决策和路径优化。这类算法能够通过大量的训练数据和自主探索，学习到高效的路径规划策略，适应动态障碍和多机器人协同作业需求。与传统算法相比，深度强化学习算法在处理高维状态空间、实时性以及灵活性方面具有明显优势，显著提升了集群机器人在复杂任务中的作业效率和鲁棒性。然而，深度强化学习算法仍面临训练时间长、样本效率低以及对环境依赖性强等挑战，需要在算法优化和应用场景拓展方面持续研究。

……

##### **1.2.4 待定相关研究**

- **技术研究补充**：根据最终的研究结果，再补充一项技术相关的研究介绍，目前还没有确定最终实验内容。



#### **1.3 研究意义与创新点**

具体需要更改

**1.3.1 政策与市场需求背景**

随着智能物流和仓储自动化的迅猛发展，对机器人协同作业能力的需求日益提升。这不仅响应了国家推动智能制造和工业自动化的政策号召，也契合了市场对高效、灵活物流解决方案的迫切需求。集群机器人作为智能物流系统的重要组成部分，其协同工作的能力直接影响整个物流流程的效率与可靠性。因此，提升集群机器人的协同作业能力，具有重要的现实意义和广阔的应用前景。

**1.3.2 创新设计理念**

本文提出的协同路径规划方法，旨在使集群机器人能够高效地完成复杂的物流任务，充分体现了智能化和自动化的设计理念。通过引入深度强化学习技术，协同路径规划方法不仅提升了路径规划的智能化水平，还增强了多机器人系统在复杂环境中的适应能力。此外，该方法为智能物流领域提供了一种全新的设计思路，有助于推动物流自动化向更高层次发展。

**1.3.3 技术创新**

本研究基于深度强化学习技术，针对复杂环境下多机器人协同作业的需求，致力于研究一种新型的路径规划算法。该算法通过优化路径选择策略，有效解决了多机器人系统中的碰撞避免和路径优化问题，从而显著提高了系统的整体作业效率。与传统路径规划方法相比，本文所提出的深度强化学习算法在处理高维状态空间、实时决策以及动态环境适应性方面具有显著优势，填补了当前多机器人协同路径规划研究中的某些空白，具有较高的学术价值和应用潜力。



#### **1.4 研究内容**

本研究将重点探讨以下几个方面：

##### **1.4.1 智能搬运车辆单车的软硬件系统**

- 设计并搭建采用麦克纳姆轮的全向移动机器人，以Jetson Nano-4GB作为计算平台，配备思岚A1激光雷达和Astra S深度相机。确保机器人具备高精度的定位、环境感知和运动控制能力。

##### **1.4.2 机器人集群的通信、建图和导航模块**

- **通信模块**：开发机器人之间及其与控制中心的通信协议，实现跨平台的ROS多机通讯。
- **建图模块**：研究环境感知和地图构建的方法，确保机器人能够在动态环境中构建精确的地图。
- **导航模块**：实现多机器人系统的路径规划和运动控制，确保机器人能够自主导航并避免碰撞。

##### **1.4.3 机器人编队与协同运动**

- 在多机器人系统中，研究编队与协同路径规划的方法，使机器人能够在指定的队形下协同作业，避免相互碰撞。重点研究领航跟随算法。

##### **1.4.4 路径规划**

- 结合传统路径规划方法（如Dijkstra、A*）和深度强化学习算法，优化领航者的路径规划，使其能够带领其他机器人保持编队形式。

##### **1.4.5 仿真与实车验证**

- 通过仿真实验和实体沙盘实验，验证所提算法的有效性和鲁棒性。仿真实验将在Gazebo环境中模拟复杂物流场景；实体实验将搭建实际的仓储沙盘，测试算法在真实环境中的性能。通过实验数据的采集与分析，评估系统的性能和改进空间。



### 2. 集群机器人微缩平台设计与实现

#### **2.1 系统总体架构**

##### **2.1.1 系统概述**：

本章节介绍多机器人集群微缩平台的整体设计与实现。该平台由若干智能搬运机器人组成，具备环境感知、自主导航、任务分配与协作能力。系统架构涵盖硬件组成、软件架构及其交互机制，确保各模块高效协同工作，以满足复杂任务的执行需求。

##### **2.1.2 工作流程**：

多机器人集群微缩平台的工作流程主要包括以下几个步骤：

- **环境感知与建图**：每台机器人通过传感器模块实时采集周围环境数据，并利用SLAM算法进行地图构建与更新。
- **任务分配与协调**：上位机通过集中控制模块，根据地图信息与任务需求，合理分配任务给各机器人，确保资源的最优利用。
- **路径规划与导航**：在接收到任务指令后，机器人利用导航堆栈进行路径规划，避开障碍物，安全高效地到达目标位置。
- **任务执行与反馈**：机器人完成指定任务后，将执行结果反馈给上位机，供进一步的数据分析与决策支持。

多机器人协同工作流程包括以下几个阶段：

1. **环境感知与建图**：各机器人利用自身传感器采集环境信息，采用SLAM算法实时构建和更新环境地图。
2. **地图融合**：通过通信网络，将各机器人构建的局部地图进行数据融合，生成全局一致的环境地图，供所有机器人共享。
3. **任务规划与分配**：基于全局地图和任务需求，进行路径规划和任务分配，考虑机器人能力和资源优化任务执行效率。
4. **领航-跟随与队形控制**：领航者按照规划路径移动，跟随者保持预定的相对位置，形成队形，并实时调整以应对环境变化和任务需求。
5. **协同执行**：各机器人按照分配的任务，协同完成目标操作，共享状态信息，确保整体任务的同步和协调。

##### **2.1.3系统架构层次**：

系统架构主要包括以下层次：

1. **感知层**：
   - **传感器模块**：各类传感器采集环境和自身状态信息。
   - **数据处理**：预处理传感器数据，提取关键信息。
2. **通信层**：
   - **无线通信网络**：实现机器人之间、机器人与上位机之间的数据传输。
   - **通信协议**：定义数据格式和传输规则，保证信息交换的可靠性。
3. **决策层**：
   - **定位与建图**：采用SLAM技术，实现自主定位和地图构建。
   - **路径规划**：基于环境地图，规划最优路径。
   - **任务分配**：根据任务需求和机器人能力，动态分配任务。
4. **控制层**：
   - **领航-跟随控制模块**：实现领航者和跟随者的运动控制。
   - **队形控制模块**：维持和调整编队队形。
5. **执行层**：
   - **运动控制单元**：驱动机器人执行运动指令。
   - **任务执行单元**：完成特定的任务操作，如搬运、检测等。

系统各层之间通过明确的接口和协议进行信息交互，实现感知、决策、控制和执行的闭环控制，确保多机器人系统的协同高效运行。



#### **2.2 单车系统组成与配置**

本节详细介绍单个智能搬运车的硬件和软件组成。

##### **2.2.1 硬件架构**

智能搬运车的硬件架构由传感模块、运动系统和主控单元三部分组成。

##### 传感模块

- **激光雷达**：采用思岚A1激光雷达，用于环境感知和建图，提供高精度的距离测量数据。
- **里程计**：用于记录车辆的行驶距离和速度，辅助实现运动控制与定位。
- **深度相机**：使用Astra S型号深度相机，支持3D点云生成、视觉SLAM建图及高级视觉导航功能，增强环境感知能力。

##### 运动系统

- **麦克纳姆轮模型**：基于麦克纳姆轮设计，推导出智能搬运车的运动学模型，分析其运动特性，支持全向移动。
- **摆式悬挂设计**：搭载麦克纳姆轮，实现四轮同时抓地，适应复杂地形，确保运行稳定，运动灵活，占用空间小。
- **驱动电机**：采用冰达定制的直流有刷金属减速电机，配备全金属齿轮，延长使用寿命，提升动力性能。

##### 主控单元

- **主控硬件**：选用Jetson Nano B01作为主控单元，提供强大的计算能力，支持复杂的算法运行和实时数据处理。

##### **2.2.2 软件架构**

##### 机器人端软件设计

- **底层驱动**：负责传感器数据的采集与处理，确保传感器与主控单元的高效通信。
- **运动控制算法**：实现基于传感器数据的运动控制逻辑，确保机器人按照预定路径和速度运动。

##### 上位机端软件设计

- **集中控制模块**：负责数据汇总与任务分配，基于全局状态信息优化任务分配策略。
- **数据管理模块**：实时收集并存储各机器人状态与任务执行数据，支持后续的数据分析与系统优化。

##### ROS操作系统平台

- **ROS结构与通信机制**：介绍ROS（机器人操作系统）的基本结构，包括节点、话题、服务等通信机制，确保系统模块间高效协作。
- **工作空间文件结构**：详细说明ROS工作空间的组织方式，便于后续实验研究与代码管理。



#### **2.3 集群系统功能模块**

本节详细介绍多机器人集群系统的功能和模块。

##### **2.3.1 多机器人通信**

##### 网络配置

为确保集群内所有机器人与上位机处于同一局域网内，首先进行网络配置。通过IP地址分配与网络参数设置，保证各设备之间能够互相通信（如可ping通）。

##### 路由器使用

采用高性能路由器，实现网络的快速配置与管理。路由器负责设备的连接管理，保证多机器人系统中各设备的稳定链接，提高通信效率。

##### **2.3.2 ROS 多机器人系统配置**

##### 基础设置

配置多机器人系统时，首先确定roscore的主节点与各个从节点。通过验证多机器人间的通信是否正常（如通过话题/rosout等），确保系统的基本通信功能。启动各机器人底盘控制节点，确保命名空间正确，避免话题和节点的冲突。

##### 多机器人控制

初步通过键盘或其他输入设备控制单个机器人，验证单个机器人的运动控制功能。随后，扩展至使用一个节点控制多台机器人，实现多机器人间的同步控制与协调，提高系统的整体工作效率。

##### **2.3.3 激光SLAM与导航**

##### 激光SLAM建图

在单台机器人上实现激光SLAM（同步定位与地图构建），生成高精度的环境地图并保存。通过集群内多台机器人共享同一地图，提升整体环境感知能力。启动激光雷达和导航堆栈节点，实现实时地图更新与导航支持。

##### 定位与导航

在多机器人系统中，确保每台机器人通过AMCL（自适应蒙特卡洛定位）与地图实现精准定位。配置多机器人导航堆栈，确保每台机器人能够自主进行路径规划与导航，避开动态和静态障碍物，安全高效地完成任务。



### 第3章 集群机器人编队控制与领航-跟随算法研究

#### 3.1 领航-跟随算法原理

在多机器人系统中，领航-跟随（Leader-Follower）算法是一种常用的编队控制方法，旨在通过协调多台机器人，实现队形保持和协同作业。本节将详细介绍领航-跟随算法的基本概念、原理及其应用。

##### 3.1.1 领航-跟随模型概述

领航-跟随模型是一种基于层级结构的多机器人协同控制模型。该模型中，领航者（Leader）负责确定整个队伍的运动轨迹和速度，通常通过预设路径规划算法或实时决策来引导队伍。跟随者（Follower）则根据领航者的运动状态，调整自身的位置和速度，以保持预定的相对位置和队形。

领航-跟随模型的优势在于控制结构简单，易于实现。同时，通过合理的设计，还能保证系统的鲁棒性和适应性，适应不同的任务需求和环境变化。

##### 3.1.2 算法原理

领航-跟随算法的核心在于：

- **相对位置保持**：跟随者需要获取领航者的位置信息，计算期望的相对位置与实际位置之间的偏差。
- **控制律设计**：根据偏差，设计控制律来调整跟随者的速度和方向，使其逐步趋近于期望位置。
- **信息获取与通信**：跟随者通过传感器测量、通信网络等方式获取领航者的位置和速度信息。

常用的控制方法包括：

- **位置控制**：采用位置误差反馈控制，使跟随者跟踪领航者的轨迹。
- **速度匹配**：调整跟随者的速度，使其与领航者保持一致。
- **队形保持**：通过预设的编队矩阵，保持跟随者之间的相对位置关系。

数学上，领航-跟随控制律可表示为：

![image-20250123175932938](https://raw.githubusercontent.com/dhw2536/Picture/main/202501232208603.png)



#### 3.2 同构多机器人系统的领航-跟随实现策略

在同构多机器人系统中，机器人在硬件和软件配置上完全一致，便于实现统一的控制策略和通信协议。本节探讨三辆同构机器人实现领航-跟随和编队控制的方法。

##### **3.2.1 系统配置**

- **硬件配置**：
  - **传感器**：每台机器人均配备激光雷达、摄像头、IMU 等传感器，用于环境感知和自身定位。
  - **计算单元**：嵌入式计算平台，运行控制算法和通信程序。
  - **通信模块**：无线通信设备，实现机器人之间的数据交换。
- **软件配置**：
  - **操作系统**：运行 ROS（Robot Operating System）等机器人操作系统，提供底层驱动和通信支持。
  - **控制算法**：实现领航-跟随控制律、路径规划、队形控制等功能模块。
  - **通信协议**：采用统一的通信协议，保证信息交换的可靠性和实时性。

##### **3.2.2 领航-跟随实现**

- **领航者路径规划**：
  - 使用全局路径规划算法（如 A* 算法、Dijkstra 算法）或局部路径规划算法（如动态窗法、人工势场法）生成领航者的运动轨迹。
  - 考虑环境障碍物和机器人运动学约束，生成可行的路径。
- **跟随者控制策略**：
  - **信息获取**：跟随者通过无线通信或视觉、激光等传感器获取领航者的实时位置和速度信息。
  - **控制律应用**：根据领航-跟随控制律，计算控制输入，调整自身运动。
  - **误差修正**：实时计算位置和速度误差，动态调整控制参数，提高跟随精度。

##### **3.2.3 队形控制策略**

- **预设队形矩阵**：定义编队中各个跟随者相对于领航者的期望位置，可形成不同的队形，如直线队列、矩形队列、三角队形等。
- **动态调整**：
  - **避碰策略**：当环境中存在障碍物或其他干扰时，跟随者需调整自身位置，避免碰撞。
  - **队形变换**：根据任务需求，实时变换队形，以适应不同的环境和目标。
- **控制实现**：
  - **位置跟踪**：跟随者通过 PID 控制等方法，精确跟踪期望的位置和速度。
  - **协同同步**：各跟随者之间共享状态信息，协同调整，保证队形的整体稳定性。



#### 3.3 异构多机器人系统的领航-跟随实现策略

在异构多机器人系统中，机器人在硬件配置、传感器类型、运动能力等方面存在差异，实现领航-跟随和编队控制面临更多挑战。本节探讨四辆异构机器人实现协同作业的方法。

##### **3.3.1 系统配置**

- **硬件差异**：
  - **传感器多样性**：不同机器人可能配备激光雷达、超声波传感器、视觉系统等不同类型的传感器。
  - **运动学模型**：机器人可能具有不同的轮式、履带式等运动机构，导致运动学特性不同。
- **通信与计算能力**：
  - **通信协议**：可能使用不同的通信接口和协议，需要进行兼容性处理。
  - **计算资源**：各机器人计算能力不一致，需要分配合适的计算任务。

##### **3.3.2 领航-跟随实现**

- **统一的通信框架**：
  - **路由器：**主要是通过外置路由器进行通信
  - **中间件**：采用 ROS 等机器人中间件，实现异构设备之间的通信和数据共享。
  - **协议转换**：设计通信协议转换模块，确保不同通信标准的兼容。
- **传感器数据融合**：
  - **多传感器融合算法**：利用卡尔曼滤波、粒子滤波等方法，融合来自不同传感器的数据，提高位置信息的准确性。
  - **感知共享**：通过通信网络，共享环境感知信息，构建全局环境模型。
- **差异化控制策略**：
  - **自适应控制**：根据各机器人的运动学特性，设计自适应的控制律。
  - **增益调节**：调整控制增益，补偿由于硬件差异带来的性能差异。

##### **3.3.3 队形控制策略**

- **任务分配与角色设定**：
  - **领航者选择**：根据机器人性能，选择最适合的机器人作为领航者。
  - **任务划分**：根据机器人能力，分配不同的任务角色，如侦察、搬运、支援等。
- **动态协调机制**：
  - **协同决策**：各机器人之间共享任务状态和环境信息，协同决策队形调整和路径规划。
  - **故障容错**：当某一机器人出现故障时，系统能动态调整队形，继续完成任务。



#### 3.4 多车协同工作与系统框架图

本节将介绍多车协同工作的具体流程，并通过系统框架图展示各个车如何配合完成复杂任务。

##### 3.4.1 多车协同工作

- **领航跟随**：一台主车进行路径规划，其余车辆根据主车的位置和方向进行跟随，形成稳定的队形。
- **建图导航**：各车分别采集环境数据，合成共享地图，实现全局导航。

##### 3.4.2 系统框架图

- **网络结构**：展示多车系统的网络结构，包括各车之间和上位机之间的通信连接。
- **数据流和控制逻辑**：展示多车系统的数据流和控制逻辑，包括传感器数据处理、路径规划和队形控制等模块。





### 第4章 集群机器人协同路径规划算法研究

#### **4.1 传统路径规划算法分析**

##### **4.1.1 路径规划的基本原理**

路径规划是机器人学中的核心问题，旨在为机器人找到一条从起始位置到目标位置的可行路径，同时避开障碍物并满足优化目标，如最短路径、最小能耗或最短时间等。传统的路径规划算法通常基于已知的环境信息，利用图搜索、优化和几何方法来生成路径。这些算法在静态和已知环境中表现良好，但在动态或未知环境中可能存在局限性。

##### **4.1.2 集中式与分布式路径规划方法**

在多机器人系统中，路径规划方法可分为集中式和分布式两种：

- **集中式路径规划**：由中央控制器收集所有机器人的位置信息和环境信息，统一规划所有机器人的路径。优点是可以整体优化整个系统的性能，但缺点是计算量大，易于产生单点故障，且不具备良好的扩展性。
- **分布式路径规划**：每个机器人根据自身的感知和与邻居机器人的通信，独立规划自身的路径。该方法具有良好的扩展性和鲁棒性，但可能导致整体性能的次优，且对机器人之间的协调性要求较高。

##### **4.1.3 传统路径规划算法在机器人中的应用**

传统的路径规划算法包括：

- **基于图搜索的算法**：如Dijkstra算法、A*算法等，利用搜索空间的表示，对路径进行全局优化。这些算法在静态、已知环境中性能优异，但计算复杂度较高。
- **基于采样的算法**：如快速随机树（RRT）和概率道路图（PRM），通过在空间中随机采样以生成可行路径，适用于高维空间的路径规划。
- **基于优化的算法**：如梯度下降法、变分法等，通过构建代价函数并优化以找到最优路径。

虽然上述算法在单机器人路径规划中取得了成功，但在多机器人协同和动态环境中，仍需要更为先进和智能的方法来满足复杂任务需求



#### **4.2 深度强化学习原理与应用框架**

##### **4.2.1 强化学习基础**

- **强化学习（Reinforcement Learning, RL）概述**
  强化学习是一种通过与环境交互、获取奖励信号来学习最优策略的机器学习方法。代理（Agent）通过采取动作与环境（Environment）互动，目的是最大化长期回报。核心概念包括状态（State）、动作（Action）和奖励（Reward）。强化学习算法通过试错过程不断优化策略，常见的算法有Q-learning、SARSA、Policy Gradient等。

- 强化学习的基本元素包括：

  - **状态空间（State Space）**：环境的所有可能状态集合，智能体需要感知当前状态。
  - **动作空间（Action Space）**：智能体在每个状态下可执行的动作集合。
  - **策略（Policy）**：映射状态到动作的规则，决定智能体在每个状态下采取的动作。
  - **奖励函数（Reward Function）**：评估智能体在特定状态下采取某一动作后所获得的反馈，指导策略的优化。
  - **价值函数（Value Function）**：评估在某一状态或状态-动作对下，智能体未来能够获得的累积奖励期望。

  深度强化学习（Deep Reinforcement Learning）将深度神经网络与强化学习相结合，利用神经网络强大的函数逼近能力，解决高维状态和动作空间下的复杂决策问题。

##### **4.2.2 Transformer与深度强化学习的结合**

- **Transformer模型简介**
  Transformer是一种基于自注意力机制的深度学习架构，最初用于自然语言处理任务。它的优势在于能够捕捉长时依赖关系，尤其适合处理时序性任务，如导航和路径规划。
- **深度强化学习中的Transformer应用**
  在路径规划任务中，使用Transformer来处理环境的观测数据（如图像信息）和目标位置，从而提高导航策略的精度和效率。GoT-GTRL（Goal-guided Transformer-enabled Reinforcement Learning）正是利用Transformer架构，使机器人能够在没有地图的情况下，仅凭RGB图像和目标信息自主导航。

##### **4.2.3 GoT-GTRL框架**

目标引导的Transformer强化学习（Goal-guided Transformer-enabled Reinforcement Learning，GoT-GTRL）框架融合了Transformer与强化学习，用于机器人无图导航。其主要特点包括：

- **输入**：机器人摄像头捕获的RGB图像序列和目标位置的极坐标信息。
- **模型架构**：利用Transformer处理时序图像数据，提取环境特征，并结合目标信息，生成决策。
- **输出**：机器人控制指令，如线速度和角速度等。
- **训练算法**：采用软演员-评论家（Soft Actor-Critic，SAC）算法，通过最大化预期奖励来优化策略，提升导航性能。

GoT-GTRL框架使机器人能够在未知环境中，仅凭传感器数据和目标信息，实现自主导航和路径规划。



#### **4.3 GoT-GTRL路径规划设计**

##### **4.3.1 状态空间设计**

在GoT-GTRL框架中，状态空间由机器人感知的环境信息和目标位置信息组成：

- **环境感知**：通过鱼眼摄像头获取的RGB图像序列，提供广角的环境视野。
- **目标信息**：目标位置相对于机器人的极坐标表示，包括距离和方位角。

这种状态表示方式使机器人能够专注于当前的导航目标，充分利用视觉感知信息，而无需构建环境的全局地图。

##### **4.3.2 动作空间定义**

机器人需要连续控制以实现平滑运动，因此动作空间被定义为连续空间，包括：

- **线速度（v）**：机器人前进或后退的速度。
- **角速度（ω)**：机器人旋转的速度，控制转向。

利用策略网络，在给定状态下输出连续的控制指令，提高导航的灵活性和精确性。

##### **4.3.3 奖励函数设计**

奖励函数的设计直接影响强化学习的效果。为了引导机器人朝向目标高效、安全地移动，奖励函数包括：

- **距离奖励**：机器人接近目标时给予正奖励，远离目标时给予负奖励，鼓励缩短与目标的距离。
- **碰撞惩罚**：机器人与障碍物发生碰撞时给予大幅负奖励，防止碰撞。
- **时间效率**：考虑到导航的时间效率，可以对每一步给予微小的惩罚，鼓励机器人以较少的步数到达目标。
- **平滑运动**：对过大的加速度或急转弯给予惩罚，促使机器人采取平滑的运动轨迹。

**4.3.4 算法实施流程**

基于GoT-GTRL的路径规划算法实施流程如下：

1. **初始化**：设置神经网络参数、强化学习超参数和环境模拟器。
2. **环境感知**：机器人通过摄像头获取当前时刻的RGB图像序列，并获取目标位置的极坐标信息。
3. **状态处理**：将感知到的图像和目标信息输入Transformer模型，提取特征表示。
4. **动作决策**：策略网络根据提取的特征，输出连续的动作指令（线速度和角速度）。
5. **执行动作**：机器人在环境中执行所选动作，更新位姿。
6. **获得奖励**：根据新的状态和奖励函数，计算即时奖励。
7. **策略更新**：利用SAC算法，基于收集的状态、动作、奖励和下一状态数据，更新策略网络和价值网络参数。
8. **循环迭代**：重复步骤2至7，不断训练和优化策略，直到收敛或达到预设的性能指标。



### 第5章 集群机器人算法验证

#### 5.1 集群机器人领航跟随与队形控制

在集群机器人系统中，实现多机器人协同运动与队形控制是关键问题之一。领航-跟随（Leader-Follower）方法是常用的队形控制策略，通过指定领航机器人，其余机器人作为跟随者，根据领航者的位置和运动状态调整自身，以维持预定的队形。

**5.1.1 多车同构机器人领航跟随方法验证**

- **定位与领航-跟随系统的实现**

  - **定位系统：**

    为了确保每个机器人能准确获取自身位置，系统使用ROS中的TF（Transform）坐标变换功能。每个机器人通过传感器获取自身位置信息，并广播到全局坐标系中。机器人之间通过订阅彼此的TF信息，实时了解其他机器人的位置和姿态。

  - **领航-跟随功能：**

    指定机器人`robot_0`为领航者，由操作者通过键盘或遥控器控制其运动。跟随机器人（如`robot_1`和`robot_2`）通过获取领航者的位置信息，使用领航-跟随算法调整自身速度和方向，以保持预定的相对位置。

- **队形控制的实现**

  - **队形算法：**

    实现多种队形控制算法，如纵队、横队、楔形等。每种队形由一组相对位移和角度定义，跟随机器人根据领航者的位置，加上队形中的相对偏移，计算期望的位置。

  - **控制策略：**

    跟随机器人使用如下控制律：

    ![image-20250123194814807](https://raw.githubusercontent.com/dhw2536/Picture/main/202501232208604.png)

- **队形切换**

通过在ROS中发布`/group_type`话题，机器人可以实时接收队形变换指令。系统根据指令切换到新的队形，跟随机器人重新计算期望位置，实现动态队形调整。

- **实验结果**

在Gazebo仿真环境和实车验证中，测试了领航-跟随和队形控制算法。结果显示，跟随机器人能够准确跟踪领航者，并根据指令实现不同队形的切换，验证了方法的有效性。

**5.1.2 多车异构机器人领航跟随方法**

在实际应用中，群体机器人往往由不同类型、不同功能的机器人组成，即异构机器人系统。实现异构机器人之间的协同与队形控制，需要解决通信、控制接口和动态特性差异等问题。

**系统架构**

- **网络配置：**

  将不同类型的机器人连接到同一网络环境中，确保它们能够通过ROS主节点进行通信。通过设置ROS Master URI，所有机器人连接到统一的ROS主节点，实现信息共享。

- **通信与数据融合：**

  使用ROS的消息机制，实现异构机器人之间的通信。定义统一的消息格式和通信协议，确保不同机器人能够理解和处理接收到的信息。

**领航-跟随控制的实现**

- **控制策略适应性：**

  针对异构机器人的动态特性，调整控制参数。对于速度较快的机器人，使用较大的控制增益；对于响应较慢的机器人，适当降低增益，防止超调和振荡。

- **抽象控制层：**

  建立一个抽象的控制层，将高层次的运动指令（如目标位置、速度）映射到各机器人具体的控制命令。这种方法可以屏蔽底层硬件差异，提高系统的可扩展性。

**实验验证**

在实际测试中，选取了冰达和轮趣两种类型的机器人组成的异构系统。通过统一的领航-跟随控制策略，三辆冰达机器人能够跟随轮趣机器人，以指定的相对位置移动。实验结果表明，该方法能够有效应对异构机器人系统的协同控制问题。



#### 5.2 集群机器人协同路径规划

**5.2.1 协同路径规划与避障**

- **协同路径规划：**

  - 基于传统A*算法，考虑其他机器人的动态位置，规划路径时避免潜在的碰撞。使用时间拓展的节点表示方法，将时间维度加入路径规划，确保机器人在空间和时间上都不发生冲突。
  - 保证机器人保持统一队列并完成路径规划任务。

- **避障机制：**

  - **静态障碍物避障：**

    利用环境地图，机器人在规划路径时避开已知的静态障碍物。使用栅格地图或拓扑地图表示环境，路径规划算法基于此地图进行。

  - **动态障碍物避障：**

    机器人实时检测环境中的动态障碍物，如行人、其他移动物体。使用传感器数据更新环境模型，结合局部避障算法（如DWA算法、人工势场法），在保持总体路径的情况下进行局部调整。

- **实验测试**

  - **场景设置：**

    在仿真和真是环境中，设置复杂的障碍物场景，包括交叉路径、狭窄通道等。机器人需要协同规划路径，避免相互碰撞和与障碍物的碰撞。

  - **结果分析：**

    实验结果显示，机器人能够成功避开静态和动态障碍物，顺利到达目标位置。协同路径规划算法有效地解决了多机器人间的冲突，提高了全局效率。

#### 5.3 基于 GoT-GTRL路径规划算法的训练与验证

##### **5.3.1 GoT-GTRL深度强化学习算法训练与优化**

**训练过程**

- **仿真环境搭建：**

  使用Gazebo模拟器构建多种复杂环境，包括不同障碍物布局、动态元素等。

- **强化学习框架：**

  选择SAC（Soft Actor-Critic）算法，具有稳定性和高效性。机器人在仿真环境中与环境交互，基于状态和奖励更新策略。

- **奖励设计：**

  奖励函数鼓励机器人快速到达目标，惩罚碰撞和偏离最优路径的行为。具体设计包括距离奖励、时间奖励、碰撞惩罚等。

**模型训练与优化**

- **超参数调整：**

  调整学习率、折扣因子、探索策略等超参数，提高训练效率和效果。

- **收敛性分析：**

  通过绘制学习曲线，观察累计奖励的变化，判断模型的收敛情况。

##### **5.3.2 仿真实验验证**

- **测试场景：**

  在不同复杂度的环境中测试训练好的模型，包括未知环境、动态障碍物环境等。

- **性能评估：**

  评估指标包括成功率、平均路径长度、碰撞次数等。结果显示，GoT-GTRL算法在复杂环境中表现出良好的导航能力。

##### **5.3.3 实车验证与“Sim-to-Real”迁移**

- **仿真到现实的迁移：**

  使用域随机化和迁移学习技术，将模型从仿真环境迁移到实际机器人平台。通过在仿真训练中引入噪声和不确定性，增强模型的泛化能力。

- **实车实验：**

  在实际环境中部署模型，机器人成功完成了自主导航和避障任务。

- **结果分析：**

  实验证明，基于深度强化学习的路径规划方法在实际应用中具有可行性和有效性，为复杂环境下的机器人导航提供了一种新途径。



### 第6章 总结与展望

#### 6.1 研究成果总结

本论文围绕编队作业场景下的群体机器人协同与路径规划问题，进行了深入研究和实践。主要成果如下：

1. **领航-跟随与队形控制：** 实现了同构和异构多机器人系统的领航-跟随控制方法。通过精准的定位和通信，实现了多种队形的动态切换，提高了编队的灵活性和适应性。
2. **协同路径规划与避障：** 开发了考虑机器人间避碰的协同路径规划算法，成功解决了多机器人在复杂环境中的路径冲突问题。机器人能够在动态环境中避开障碍物，体现了系统的鲁棒性。
3. **基于深度强化学习的路径规划：** 引入GoT-GTRL算法，利用深度强化学习实现了复杂环境下的机器人自主导航。通过仿真和实车验证，证明了该方法的有效性，为机器人路径规划提供了新的思路。



#### 6.2 研究限制与未来工作

**研究限制：**

- **算法的可扩展性：** 当前的协同控制和路径规划算法在机器人数量较多时，计算复杂度较高，影响系统的实时性。
- **仿真与现实差距：** 尽管采取了“仿真到现实”迁移方法，但仿真环境仍无法完全模拟现实中的不确定性，影响了模型的泛化能力。
- **异构系统的复杂性：** 异构机器人系统中，不同硬件和软件平台的兼容性问题仍需进一步解决。

**未来工作：**

- **算法优化与并行化：** 研究更加高效的算法，利用分布式计算和并行处理，提高系统的可扩展性和实时性。
- **增强学习的泛化能力：** 引入多任务学习和元学习等方法，提升深度强化学习模型在不同环境下的适应性。
- **异构系统标准化：** 制定统一的接口和通信协议，开发跨平台的机器人操作系统，降低异构系统集成的难度。
- **人机协同与安全性：** 研究群体机器人与人类协同工作的机制，注重系统的安全性和可靠性，促进机器人更好地服务于实际应用。

综上所述，本论文的研究为群体机器人协同控制与路径规划提供了有效的解决方案，但仍有提升空间。未来将继续深入探索，推动相关技术的发展和应用。



