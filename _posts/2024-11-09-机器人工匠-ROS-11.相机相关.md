---
layout:     post
title:      ROS - 11.相机相关
subtitle:   机器人操作系统ROS快速入门教程
date:       2024-11-09
author:     Space
header-img: img/the-first.png
catalog:   true
tags:
    - ROS


---



# 机器人操作系统 ROS 

### 69. ROS 中的相机话题

### ROS 相机数据使用学习笔记

**课程内容：**

- 探讨机器人如何通过相机进行机器视觉感知，并在ROS中获取和处理相机数据。

**机器视觉简介：**

- 机器人使用相机进行视觉感知。
- 相机类型包括普通彩色相机和RGBD相机。
- 应用包括物体识别、定位、3D建模和多模态融合。

**ROS中的相机数据获取：**

- 相机数据通常通过话题发布。
- 相机话题数量较多，包含不同类型的图像数据。

**相机话题详解：**

1. **`/image_raw`**：
   - 发布相机的原始数据（黑白图像）。
2. **`/image_color`**：
   - 发布RGB格式的彩色图像数据。
3. **`/image_color_rect`**：
   - 发布畸变校正后的彩色图像。
4. **`/camera_info`**：
   - 发布相机参数，可用于自行进行畸变校正。

**相机数据的畸变校正：**

- 相机镜头存在畸变，需要校正以获得准确图像。
- 校正后的图像对目标识别和视觉SLAM至关重要。

**ROS中相机图像话题的使用：**

- 通常订阅`/image_color`话题获取校正后的彩色图像。
- 图像消息包的发送频率与相机帧率相关。
- 消息格式为`sensor_msgs/Image`类型。

**图像数据处理：**

- 通常将图像消息转换为OpenCV的`cv::Mat`类型进行处理。
- ROS中的消息格式不需要深入了解，但需要知道转换方法。

**后续课程预告：**

- 将使用C++和Python处理机器人相机数据。
- 通过目标跟踪案例了解ROS中相机图像处理流程。

**总结：**

- 相机是机器人重要的感知设备，ROS提供了丰富的话题获取相机数据。
- 需要理解不同类型的相机话题以及如何进行畸变校正。
- 通过后续实践课程，将学习如何在ROS中处理和应用相机数据。



### 70. 相机图像获取的 C++ 实现

**课程内容：**

- 使用C++从机器人相机获取图像数据，并进行处理。

**实验目标：**

- 从相机话题获取图像数据。
- 使用OpenCV显示相机图像。

**创建软件包：**

1. **包名**：`cv_package`。
2. **依赖项**：`roscpp`, `cv_bridge`, `image_transport`。

**节点代码编写：**

1. **文件名**：`cv_node.cpp`。
2. **包含头文件**：
   - `ros/ros.h`：ROS C++ 头文件。
   - `cv_bridge/cv_bridge.h`：图像格式转换头文件。
   - `sensor_msgs/Image.h`：图像消息类型头文件。
   - `opencv2/opencv.hpp`：OpenCV 头文件。

**程序代码：**

1. **引入命名空间**：
   - 使用`using namespace cv;`简化OpenCV函数调用。
2. **初始化节点**：
   - `ros::init(argc, argv, "cv_node");`
3. **定义`NodeHandle`对象**：
   - `ros::NodeHandle nh;`
4. **定义图像订阅者**：
   - 订阅`/camera/color/rect`话题。
5. **定义回调函数**：
   - `void cameraCallback(const sensor_msgs::ImageConstPtr& msg);`
6. **图像显示窗口**：
   - 创建名为"RGB"的窗口。
7. **使用`ros::spin`保持运行**。

**回调函数实现：**

1. **图像格式转换**：
   - 使用`cv_bridge::CvtColor`将ROS图像消息转换为OpenCV的`cv::Mat`格式。
2. **异常处理**：
   - 使用`try-catch`捕获转换过程中的异常。
3. **图像显示**：
   - 使用`cv::imshow`显示图像。
   - 使用`cv::waitKey`暂停回调函数，以便图像显示。

**编译规则添加：**

1. **打开`CMakeLists.txt`**。
2. **添加`find_package`指令**：
   - 引入OpenCV环境配置。
3. **添加包含目录**：
   - `include_directories(include ${catkin_INCLUDE_DIRS} ${OpenCV_INCLUDE_DIRS})`。
4. **添加库文件列表**：
   - 在`target_link_libraries`中添加OpenCV库。

**编译节点：**

1. **进入工作空间**。
2. **执行`catkin_make`编译**。

**测试节点：**

1. **启动仿真环境**。
2. **运行节点**：
   - 观察名为"RGB"的窗口中显示的相机图像。

**后续课程预告：**

- 实现对图像中物体的识别和定位。

**总结：**

- 成功从相机话题获取图像数据，并使用OpenCV显示图像。
- 学习了如何在ROS中处理相机图像数据。
- 为后续图像处理和计算机视觉任务打下基础。



### 71. 颜色目标识别与定位的 C++ 实现

**课程内容：**

- 使用C++和OpenCV处理ROS中的相机图像数据，进行颜色特征提取和空间定位。

**实验目标：**

- 从相机话题获取图像数据。
- 转换颜色空间从RGB到HSV。
- 对图像进行二值化处理。
- 提取目标物体并计算其在图像中的位置。

**任务分解：**

1. **颜色空间转换**：从RGB转换到HSV空间。
2. **图像二值化**：通过设置阈值提取目标物体。
3. **目标像素统计**：计算目标物体的中心坐标。

**颜色空间转换原因：**

- RGB颜色空间中颜色分布不规律，难以分割。
- HSV空间更容易进行颜色分割，受光照影响小。

**HSV颜色模型：**

- **H**：色调，表示颜色类型。
- **S**：饱和度，表示颜色的鲜艳程度。
- **V**：亮度，表示颜色的明暗程度。

**节点代码编写：**

1. **文件名**：`cvhsv_node.cpp`。
2. **包含头文件**：
   - `ros/ros.h`：ROS C++ 头文件。
   - `cv_bridge/cv_bridge.h`：图像格式转换头文件。
   - `sensor_msgs/Image.h`：图像消息类型头文件。
   - `opencv2/opencv.hpp`：OpenCV 头文件。

**程序代码：**

1. **引入命名空间**：
   - 使用`using namespace cv;`简化OpenCV函数调用。
2. **主函数**：
   - 初始化ROS节点。
   - 订阅相机话题，设置回调函数。
   - 创建用于调节HSV阈值的GUI窗口和滑杆。
   - 创建显示原始图像、HSV图像和二值化图像的窗口。
   - 循环等待新图像并调用回调函数。

**回调函数实现：**

1. **图像格式转换**：
   - 将ROS图像消息转换为OpenCV的`cv::Mat`格式。
2. **颜色空间转换**：
   - 使用`cvtColor`函数将RGB图像转换为HSV图像。
3. **图像二值化**：
   - 使用`inRange`函数根据阈值分割图像。
4. **目标像素统计**：
   - 计算二值化图像中目标物体的中心坐标。
5. **图像显示**：
   - 使用`imshow`函数显示处理后的图像。

**编译规则添加：**

1. **打开`CMakeLists.txt`**。
2. **添加`find_package`指令**：
   - 引入OpenCV环境配置。
3. **添加包含目录**：
   - 添加OpenCV头文件路径。
4. **添加节点编译规则**：
   - 添加节点源文件和链接OpenCV库。

**测试节点：**

1. **启动仿真环境**。
2. **运行节点**：
   - 观察不同窗口中显示的图像和调节阈值的效果。

**后续课程预告：**

- 实现机器人对目标颜色球的跟随运动。

**总结：**

- 成功实现了从相机话题获取图像数据，并使用OpenCV进行处理。
- 学习了如何在ROS中进行图像的颜色空间转换和二值化处理。
- 掌握了计算图像中物体中心坐标的方法，为后续目标跟踪任务打下基础。



### 72. ROS 颜色目标跟随的 C++ 实现

**课程内容：**

- 将机器人控制与视觉处理结合，实现机器人对特定颜色目标的跟随运动。

**实验目标：**

- 利用相机图像数据控制机器人移动，使其跟随特定颜色的目标球。

**实现步骤：**

1. **分析目标球位置**：通过相机图像识别目标球，并确定其在图像中的位置。
2. **计算偏差**：计算目标球位置与图像中心的偏差。
3. **控制机器人移动**：根据偏差调整机器人的速度和方向，实现跟随。

**关键概念：**

- 目标球在图像中的位置与机器人的实际位置是相关联的。
- 通过调整机器人的速度和方向，可以使其对准并跟随目标球。

**节点代码编写：**

1. **文件名**：`cvfollow_node.cpp`。
2. **包含头文件**：
   - `ros/ros.h`：ROS C++ 头文件。
   - `cv_bridge/cv_bridge.h`：图像格式转换头文件。
   - `sensor_msgs/Image.h`：图像消息类型头文件。
   - `opencv2/opencv.hpp`：OpenCV 头文件。
   - `geometry_msgs/Twist.h`：速度控制消息类型头文件。

**程序代码：**

1. **引入命名空间**：
   - 使用`using namespace cv;`简化OpenCV函数调用。
2. **定义全局变量**：
   - 定义速度控制消息和发布对象。
3. **主函数**：
   - 初始化ROS节点和订阅相机话题。
   - 初始化速度发布对象。
   - 创建GUI窗口和滑杆控件用于调节HSV阈值。
   - 创建显示窗口并进入循环，调用`ros::spin`保持节点运行。
4. **回调函数**：
   - 转换图像格式并进行颜色分割。
   - 计算目标球中心坐标。
   - 根据图像中目标球的位置计算机器人的速度（前后移动和旋转）。
   - 发布速度消息控制机器人移动。

**编译规则添加：**

1. **打开`CMakeLists.txt`**。
2. **添加`find_package`指令**：引入OpenCV环境配置。
3. **添加包含目录**：设置OpenCV头文件路径。
4. **添加节点编译规则**：添加节点源文件和链接OpenCV库。

**测试节点：**

1. **启动仿真环境**。
2. **运行节点**：
   - 观察机器人是否能根据相机图像中目标球的位置进行跟随。

**后续课程预告：**

- 进一步优化跟随算法，提高机器人的响应速度和准确性。

**总结：**

- 成功实现了机器人对特定颜色目标的跟随运动。
- 学习了如何结合图像处理和机器人控制来实现复杂任务。
- 为后续更高级的机器人视觉任务打下了基础。



### 73. ROS 人脸检测的 C++ 实现

**课程内容：**

- 学习如何在ROS中使用OpenCV进行人脸检测，并在图像中标注人脸位置。

**实验目标：**

- 从机器人相机图像中检测出人脸，并在图像上标注。

**关键技术：**

- 使用基于Haar特征的级联分类器进行人脸检测。

**Haar特征和级联分类器：**

- Haar特征：表示明暗几何关系的模板，用于特征匹配。
- 级联分类器：多级检测结构，通过一系列Haar特征模板匹配来识别人脸。

**节点代码编写：**

1. **文件名**：`cv_face_detect.cpp`。
2. **包含头文件**：
   - `ros/ros.h`：ROS C++ 头文件。
   - `cv_bridge/cv_bridge.h`：图像格式转换头文件。
   - `sensor_msgs/Image.h`：图像消息类型头文件。
   - `opencv2/opencv.hpp`：OpenCV 头文件。
   - `opencv2/objdetect.hpp`：OpenCV 检测函数头文件。

**程序代码：**

1. **引入命名空间**：
   - 使用`using namespace cv;`简化OpenCV函数调用。
2. **定义全局变量**：
   - `CascadeClassifier`：用于加载人脸检测分类器。
   - `Mat`：存储图像数据。
   - `vector<Rect>`：存放检测到的人脸位置。
3. **主函数**：
   - 初始化ROS节点。
   - 订阅相机图像话题。
   - 加载人脸检测分类器。
   - 创建显示人脸检测结果的窗口。
   - 进入循环，调用`ros::spin`保持节点运行。
4. **回调函数**：
   - 转换图像格式。
   - 转换彩色图像为灰度图像。
   - 进行人脸检测。
   - 标注并显示检测到的人脸。

**编译规则添加：**

1. **打开`CMakeLists.txt`**。
2. **添加`find_package`指令**：引入OpenCV环境配置。
3. **添加包含目录**：设置OpenCV头文件路径。
4. **添加节点编译规则**：添加节点源文件和链接OpenCV库。

**测试节点：**

1. **启动仿真环境**。
2. **运行节点**：
   - 观察图像窗口中是否正确标注了人脸。

**后续课程预告：**

- 进一步探索OpenCV在机器人视觉中的应用。

**总结：**

- 成功实现了在ROS中使用OpenCV进行人脸检测。
- 学习了Haar特征和级联分类器的基本概念。
- 掌握了在ROS节点中调用OpenCV函数进行图像处理的方法。



### 74. ROS 相机图像获取的 Python 实现

**课程内容：**

- 使用Python从机器人相机获取图像数据，并显示在窗口中。

**实验目标：**

- 从相机话题获取图像数据消息包。
- 使用`cv_bridge`将ROS图像消息转换为OpenCV格式。
- 使用OpenCV显示相机图像。

**创建软件包：**

1. **包名**：`image_package`。
2. **依赖项**：`roslib`, `sensor_msgs`, `cv_bridge`。

**节点代码编写：**

1. **文件名**：`cv_image_node.py`。
2. **包含模块**：
   - `roslib`：ROS Python API。
   - `cv_bridge`：图像格式转换库。
   - `sensor_msgs`：传感器消息类型库。
   - `rospy`：ROS Python实现库。

**程序代码：**

1. **初始化节点**：
   - 使用`rospy.init_node`初始化ROS节点。
2. **订阅相机话题**：
   - 订阅相机图像话题，设置回调函数`camera_callback`。
3. **回调函数**：
   - 在回调函数中，使用`cv_bridge`将ROS图像消息转换为OpenCV格式。
   - 使用OpenCV的`imshow`函数显示图像。
   - 使用`waitKey`函数暂停回调函数，以便图像显示。

**添加可执行权限：**

1. 在终端中进入Python节点文件所在的`scripts`文件夹。
2. 添加可执行权限：`chmod +x cv_image_node.py`。

**编译软件包：**

1. 退回到工作空间目录。
2. 执行`catkin_make`编译。

**运行节点：**

1. 启动仿真环境。
2. 运行节点：`rosrun image_package cv_image_node.py`。
3. 观察图像是否实时显示在窗口中。

**后续课程预告：**

- 对图像数据进行处理，实现对物体的识别和定位。

**总结：**

- 成功实现了从相机话题获取图像数据，并使用OpenCV显示图像。
- 学习了如何在ROS中使用Python进行图像处理。
- 为后续图像处理和计算机视觉任务打下了基础。

**代码示例：**

```python
#!/usr/bin/env python
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
import cv2

def camera_callback(msg):
    bridge = CvBridge()
    try:
        cv_image = bridge.imgmsg_to_cv2(msg, "bgr8")
    except CvBridgeError as e:
        print(e)

    cv2.imshow("RGB", cv_image)
    cv2.waitKey(1)

def main():
    rospy.init_node('image_listener')
    rospy.subscribe("/camera/image", Image, camera_callback)
    rospy.spin()

if __name__ == '__main__':
    main()
```

**注意：**

- 确保在`CMakeLists.txt`和`package.xml`中添加了必要的依赖项。



### 75. ROS 颜色目标识别与定位的 Python 实现

**课程内容：**

- 使用Python和OpenCV处理ROS中的相机图像数据，进行颜色特征提取和空间定位。

**实验目标：**

- 从相机话题获取图像数据。
- 转换颜色空间从RGB到HSV。
- 对图像进行二值化处理。
- 提取目标物体并计算其在图像中的位置。

**任务分解：**

1. **颜色空间转换**：从RGB转换到HSV空间。
2. **图像二值化**：通过设置阈值提取目标物体。
3. **目标像素统计**：计算目标物体的中心坐标。

**颜色空间转换原因：**

- RGB颜色空间中颜色分布不规律，难以分割。
- HSV空间更容易进行颜色分割，受光照影响小。

**HSV颜色模型：**

- **H**：色调，表示颜色类型。
- **S**：饱和度，表示颜色的鲜艳程度。
- **V**：亮度，表示颜色的明暗程度。

**节点代码编写：**

1. **文件名**：`hsv_node.py`。
2. **包含模块**：
   - `rospy`：ROS Python API。
   - `cv_bridge`：图像格式转换库。
   - `sensor_msgs`：传感器消息类型库。
   - `opencv2`：OpenCV库。

**程序代码：**

1. **引入命名空间**：
   - 使用`cv2`简化OpenCV函数调用。
2. **定义全局变量**：
   - 定义HSV颜色分割阈值变量。
   - 定义速度控制消息和发布对象（如果需要控制机器人）。
3. **主函数**：
   - 初始化ROS节点。
   - 订阅相机话题，设置回调函数。
   - 创建GUI窗口和滑杆控件用于调节HSV阈值。
   - 创建显示原始图像、HSV图像和二值化图像的窗口。
   - 进入循环，调用`rospy.spin`保持节点运行。
4. **回调函数**：
   - 转换图像格式并进行颜色分割。
   - 计算目标物体的中心坐标。
   - 使用OpenCV函数在图像中标记目标位置。

**添加可执行权限：**

1. 在终端中进入Python节点文件所在的`scripts`文件夹。
2. 添加可执行权限：`chmod +x hsv_node.py`。

**编译软件包：**

1. 退回到工作空间目录。
2. 执行`catkin_make`编译。

**运行节点：**

1. 启动仿真环境。
2. 运行节点：`rosrun image_package hsv_node.py`。
3. 观察不同窗口中显示的图像和调节阈值的效果。

**后续课程预告：**

- 进一步探索图像处理和机器人控制的结合应用。

**总结：**

- 成功实现了在ROS中使用Python进行图像的颜色空间转换和二值化处理。
- 学习了如何在ROS中进行图像处理和目标物体的空间定位。
- 为后续更高级的机器人视觉任务打下了基础。

**代码示例：**

```python
#!/usr/bin/env python
import rospy
import cv2
from cv_bridge import CvBridge
from sensor_msgs.msg import Image

def camera_callback(msg):
    bridge = CvBridge()
    try:
        cv_image = bridge.imgmsg_to_cv2(msg, "bgr8")
    except Exception as e:
        print(e)
        return

    # Convert to HSV
    hsv_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)
    # Thresholding
    mask = cv2.inRange(hsv_image, lower_bound, upper_bound)
    # Calculate centroid
    M = cv2.moments(mask)
    if M["m00"] != 0:
        cX = int(M["m10"] / M["m00"])
        cY = int(M["m01"] / M["m00"])
        cv2.circle(cv_image, (cX, cY), 5, (255, 0, 0), -1)

    cv2.imshow("HSV", hsv_image)
    cv2.imshow("Mask", mask)
    cv2.imshow("Result", cv_image)
    cv2.waitKey(1)

def main():
    rospy.init_node('hsv_node')
    rospy.Subscriber("/camera/image", Image, camera_callback)
    rospy.spin()

if __name__ == '__main__':
    main()
```

**注意：**

- 确保在`CMakeLists.txt`和`package.xml`中添加了必要的依赖项。



### 76. ROS 颜色目标跟随的 Python 实现

**课程内容：**

- 使用Python实现机器人对特定颜色目标的跟随运动。

**实验目标：**

- 利用相机图像数据控制机器人移动，使其跟随特定颜色的目标球。

**实现步骤：**

1. **分析目标球位置**：通过相机图像识别目标球，并确定其在图像中的位置。
2. **计算偏差**：计算目标球位置与图像中心的偏差。
3. **控制机器人移动**：根据偏差调整机器人的速度和方向，实现跟随。

**关键概念：**

- 目标球在图像中的位置与机器人的实际位置是相关联的。
- 通过调整机器人的速度和方向，可以使其对准并跟随目标球。

**节点代码编写：**

1. **文件名**：`follow_node.py`。
2. **包含模块**：
   - `rospy`：ROS Python API。
   - `cv_bridge`：图像格式转换库。
   - `sensor_msgs`：传感器消息类型库。
   - `geometry_msgs`：几何消息类型库，用于速度控制。

**程序代码：**

1. **初始化节点**：
   - 使用`rospy.init_node`初始化ROS节点。
2. **订阅相机话题**：
   - 订阅相机图像话题，设置回调函数`camera_callback`。
3. **发布速度控制话题**：
   - 发布速度控制话题，用于控制机器人移动。
4. **回调函数**：
   - 在回调函数中，使用`cv_bridge`将ROS图像消息转换为OpenCV格式。
   - 使用OpenCV处理图像，识别目标球并计算其位置。
   - 根据目标球位置计算机器人的速度（前后移动和旋转）。
   - 发布速度消息控制机器人移动。

**添加可执行权限：**

1. 在终端中进入Python节点文件所在的`scripts`文件夹。
2. 添加可执行权限：`chmod +x follow_node.py`。

**编译软件包：**

1. 退回到工作空间目录。
2. 执行`catkin_make`编译。

**运行节点：**

1. 启动仿真环境。
2. 运行节点：`rosrun image_package follow_node.py`。
3. 观察机器人是否能根据相机图像中目标球的位置进行跟随。

**后续课程预告：**

- 进一步探索图像处理和机器人控制的结合应用。

**总结：**

- 成功实现了在ROS中使用Python进行目标跟随运动。
- 学习了如何结合图像处理和机器人控制来实现复杂任务。
- 为后续更高级的机器人视觉任务打下了基础。

**代码示例：**

```python
#!/usr/bin/env python
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from geometry_msgs.msg import Twist

def camera_callback(msg):
    bridge = CvBridge()
    try:
        cv_image = bridge.imgmsg_to_cv2(msg, "bgr8")
    except CvBridgeError as e:
        print(e)

    # Image processing to find the target
    # Calculate the speed for robot to follow the target
    # Publish the speed command

def main():
    rospy.init_node('follow_node')
    rospy.subscribe("/camera/image", Image, camera_callback)
    rate = rospy.Rate(10)  # 10hz

    while not rospy.is_shutdown():
        # Get the latest values for the HSV thresholds
        # Publish the velocity commands
        rate.sleep()

if __name__ == '__main__':
    main()
```

**注意：**

- 确保在`CMakeLists.txt`和`package.xml`中添加了必要的依赖项。



### 77. ROS 人脸检测的 Python 实现

**课程内容：**

- 使用Python和OpenCV在ROS中实现人脸检测，并在图像中标注人脸位置。

**实验目标：**

- 从机器人相机图像中检测人脸，并在图像上标记。

**关键技术：**

- 使用基于Haar特征的级联分类器进行人脸检测。

**Haar特征和级联分类器：**

- Haar特征：表示明暗几何关系的模板，用于特征匹配。
- 级联分类器：多级检测结构，通过一系列Haar特征模板匹配来识别人脸。

**节点代码编写：**

1. **文件名**：`face_node.py`。
2. **包含模块**：
   - `rospy`：ROS Python API。
   - `cv_bridge`：图像格式转换库。
   - `sensor_msgs`：传感器消息类型库。
   - `opencv2`：OpenCV库。

**程序代码：**

1. **引入命名空间**：
   - 使用`cv2`简化OpenCV函数调用。
2. **定义全局变量**：
   - 定义人脸检测分类器。
   - 定义图像格式转换器`CvBridge`。
3. **主函数**：
   - 初始化ROS节点。
   - 订阅相机话题，设置回调函数`camera_callback`。
   - 使用`rospy.spin`保持节点运行。
4. **回调函数**：
   - 转换图像格式并进行人脸检测。
   - 在检测到的人脸周围绘制矩形框。
   - 显示标注了人脸的图像。

**添加可执行权限：**

1. 在终端中进入Python节点文件所在的`scripts`文件夹。
2. 添加可执行权限：`chmod +x face_node.py`。

**编译软件包：**

1. 退回到工作空间目录。
2. 执行`catkin_make`编译。

**运行节点：**

1. 启动仿真环境。
2. 运行节点：`rosrun image_package face_node.py`。
3. 观察图像窗口中是否正确标注了人脸。

**后续课程预告：**

- 探索更多的OpenCV图形库功能和机器视觉应用。

**总结：**

- 成功实现了在ROS中使用Python进行人脸检测。
- 学习了Haar特征和级联分类器的基本概念。
- 掌握了在ROS节点中调用OpenCV函数进行图像处理的方法。

**代码示例：**

```python
#!/usr/bin/env python
import rospy
import cv2
from cv_bridge import CvBridge
from sensor_msgs.msg import Image

def camera_callback(msg):
    bridge = CvBridge()
    try:
        cv_image = bridge.imgmsg_to_cv2(msg, "bgr8")
    except Exception as e:
        print(e)
        return

    gray_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
    face_cascade = cv2.CascadeClassifier('path_to_haarcascade_frontalface_default.xml')
    faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1, minNeighbors=5)

    for (x, y, w, h) in faces:
        cv2.rectangle(cv_image, (x, y), (x+w, y+h), (255, 0, 0), 2)

    cv2.imshow("Face Detection", cv_image)
    cv2.waitKey(1)

def main():
    rospy.init_node('face_detection_node')
    rospy.Subscriber("/camera/image", Image, camera_callback)
    rospy.spin()

if __name__ == '__main__':
    main()
```

**注意：**

- 确保在`CMakeLists.txt`和`package.xml`中添加了必要的依赖项。
- 替换`path_to_haarcascade_frontalface_default.xml`为正确的Haar特征文件路径。
