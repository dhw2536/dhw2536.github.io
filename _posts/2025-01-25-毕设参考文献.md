---
layout:     post
title:      毕设参考文献
subtitle:   xxx
date:       2025-01-25
author:     Space
header-img: img/the-first.png
catalog:   true
tags:
    - 本科毕设探索

---

**摘要：**

**引用格式：**

**可用到内容：**

**大概内容：**



# 编队作业场景下集群机器人协同路径规划研究



## 毕业设计任务书

#### **一、学生姓名：**段宏伟       **学号：**U202141170

#### **二、题目：**编队作业场景下集群机器人协同路径规划研究

#### **三、题目来源：**真实  √  自拟  □ 

#### **四、结业方式：**论文  √  设计  □

#### **五、主要内容：**

1. **集群机器人微缩平台的设计与实现：** 设计并构建基于麦克纳姆轮的全向移动机器人，集成激光雷达、深度相机、IMU等多种传感器，实现高精度的环境感知和定位功能，为后续算法研究提供硬件基础。
2. **机器人集群通信、建图和导航模块的开发：** 基于ROS平台，开发机器人集群的通信框架，实现跨平台的多机通信与协同工作；构建共享地图，支持集群机器人的协同建图与导航功能，提升整体环境感知与路径规划能力。
3. **领航-跟随算法的研究与实现：** 研究领航-跟随算法的原理，解决机器人之间的通信、定位和协同控制问题；开发稳定的队形控制算法，实现集群机器人在复杂环境中的有序编队运动，增强协同作业能力。
4. **路径规划算法的部署与创新：** 在实车平台上部署传统路径规划算法（如A*算法），评估其在实际应用中的性能；提出基于深度强化学习算法的路径规划方法，提高路径规划的效率和适应性，提升机器人在动态环境中的自主导航能力。
5. **算法的仿真与实物验证：** 利用Gazebo仿真平台和实际机器人平台，对领航-跟随、队形控制、路径规划算法进行全面的仿真与实验验证，评估算法的有效性和鲁棒性，为算法的实际应用提供支持。



#### **六、主要（技术）要求：**

1. **掌握关键技术：** 熟练掌握ROS系统的使用，熟悉Python和C++编程语言；深入理解深度强化学习和Transformer模型在路径规划中的应用，能够将其有效地融合到机器人路径规划算法中。
2. **基于ROS的多机器人通信框架：** 熟悉ROS多机通信机制，能够构建稳定高效的多机器人通信框架，实现机器人之间的数据共享与协同工作。
3. **熟悉多种传感器的集成与使用：** 熟练使用激光雷达、深度相机、IMU等传感器，具备传感器数据处理和融合的能力，实现高精度的环境感知和自主定位。
4. **领航-跟随算法的研究与实现：** 研究领航-跟随算法的原理，解决机器人之间的通信、定位和协同控制问题；开发队形控制算法，实现集群机器人稳定的编队运动，提高集群机器人在复杂环境下的协同能力。
5. **开发并优化路径规划算法：** 掌握传统路径规划算法的原理与实现，能够在实际应用中进行有效部署；能够结合深度强化学习方法，开发高效的路径规划算法，适应复杂动态环境下的机器人导航需求。



## 参考文献分析

毕业设计中心主题是“集群机器人，编队作业，路径规划，领航跟随，深度强化学习”。从中延伸出多个相关概念，显示了这些概念与中心主题的关联。具体来说：

![preview](2025-01-25-毕设参考文献.assets/cu9f3n7ftae4m6b15h60.png)

1. **协同避障和围捕** - 可能指的是机器人在执行任务时如何避免相互碰撞以及如何合作围捕目标。
2. **人工势场法** - 一种用于机器人路径规划的算法，通过构建势场来引导机器人避开障碍物。
3. **无人机** - 一种常见的集群机器人，可以用于多种任务，如监控、运输等。
4. **TD3算法** - 一种深度强化学习算法，用于解决连续动作空间中的决策问题。
5. **分层模型** - 可能指的是在机器人系统中使用的分层控制架构，以处理不同层次的决策和控制问题。
6. **除草机器人** - 一种专用机器人，可能用于农业中的自动除草任务。
7. **无人机博弈** - 可能指的是无人机在执行任务时的策略选择和对抗性决策。
8. **遗传算法** - 一种启发式搜索算法，常用于优化和搜索问题，包括机器人路径规划。
9. **自主避障** - 机器人独立识别和避开障碍物的能力。

这些概念共同构成了集群机器人在执行编队作业、路径规划和领航跟随任务时可能涉及的技术和方法。深度强化学习作为一种先进的机器学习方法，可能被用来优化这些任务中的决策过程。



## **研究综述**

#### 集群机器人系统**特性评价**研究综述

**摘要：**集群机器人系统是群体智能的一个重要应用研究领域,也是机器人系统未来发展的重要方向之一.集群机器人系统特性评价是一个极具挑战性的关键技术与理论问题,对于集群机器人系统的研究与发展具有重要意义.首先,给出了对集群机器人系统基本概念的理解,并且从多种不同角度作出了分类.其次,梳理了多个关键的集群机器人系统期望特性;在此基础上,分别从评价标准、评价指标体系和评价方法三方面对已有集群机器人系统特性评价研究成果进行了比较全面的评述.最后,分析总结了当前集群机器人系统特性评价研究工作的不足,并对未来发展方向进行了展望.

**引用格式：**[1]武文亮,周兴社,沈博,等.集群机器人系统特性评价研究综述[J].自动化学报,2022,48(05):1153-1172.DOI:10.16383/j.aas.c200964.

**可用到内容：**集群机器人系统概念、分类、优势、特性

**大概内容：**

- 首先介绍了集群机器人系统的概念，包括其组成和典型系统，以及从控制方法、协作机制等多种属性进行分类的方式。
- 接着梳理了集群机器人系统的期望特性，如自主性、智能性、协同性、灵活性、鲁棒性、可扩展性等。
- 然后详细阐述了系统自主性评价标准和系统智能性评价标准，列举了不同机构或学者提出的相关标准。
- 还比较了多种系统自主性评价指标体系。
- 之后说明了集群机器人系统特性评价的基本方法和自主性等特性的综合评价方法。
- 最后分析总结了当前研究工作的不足，并对未来发展方向进行了展望。



#### 机器人集群**路径规划**技术研究现状

**摘要：**受社会型生物群体行为启发,群体智能得到日益广泛的关注,机器人集群作为群体智能的重要承载者得到了大量研发和广泛应用。机器人集群路径规划技术作为一项核心关键技术也得到快速发展。为此全面深入地调研了机器人集群路径规划的技术发展现状,创新性地归纳了适用于不同集群规模、可扩展性要求、通信需求以及算法要求的集群规划基础计算架构,包括冗余计算架构、分布计算架构和分层计算架构。从可扩展性和适用性角度,分类梳理了最适用于机器人集群的路径规划方法,包括仿生学方法、人工势场法、几何学方法、经典搜索法和进化学习法,并为集群仿真验证研究提供了七款可免费下载或开源的机器人集群仿真验证平台。

**引用格式：**[1]高明,唐洪,张鹏.机器人集群路径规划技术研究现状[J].国防科技大学学报,2021,43(01):127-138.

**可用到内容：**机器人集群路径规划概念、

**大概内容**

1. **机器人集群概述**：受社会型生物群体行为启发，机器人集群应运而生，展现出群体智能，具备自组织和分工特征。其应用广泛，涵盖聚合、编队、运输等多种任务。机器人集群路径规划是实现导航和协调任务的关键，相比单个机器人路径规划，存在维度高、计算复杂等难点 。
2. 集群分布计算架构
   - **冗余计算架构**：将同一规划算法复制到每个机器人规划器，依赖输入状态信息一致性，适用于特定算法和小规模集群在理想通信条件下，工程中需采取措施确保信息一致 。
   - **分布计算架构**：完全分布式计算，对通信即时可靠性要求低，但对带宽要求高，适用于多种分布式算法和中等规模集群在复杂通信条件下，规模过大时规划算法收敛困难。
   - **分层计算架构**：全局集中、局部分散，对通信可靠性和带宽要求低，适用于多种算法和大规模集群在复杂通信条件下，但集群密度不能超出环境容限。
3. 集群路径规划方法
   - **仿生学方法**：受生物行为启发，如蚁群算法、鱼群算法、鸽群算法、萤火虫算法等，具有分布式、自组织、可扩展优势，但存在易陷入局部最优等问题，已有多种改进算法。
   - **人工势场法**：将工作空间定义为势场，计算简单，适用于大规模集群，但存在局部最小值和复杂环境规划难题，已有结合其他方法的改进算法 。
   - **几何学方法**：利用几何曲线生成或平滑路径，如杜宾斯曲线法、贝塞尔曲线法、毕达哥拉斯曲线法等，因模型复杂，仅适用于小规模集群。
   - **经典搜索法**：包括概率路标图、经典路径寻优法（如迪杰斯特拉算法）、启发式搜索（如算法）等，部分方法在处理大规模集群时存在可扩展性问题 。
   - **进化学习法**：包括监督学习、基于遗传算法的进化方法、强化学习等，以及基于教学 - 学习的优化算法等，用于克服传统方法的缺点。
4. **机器人集群验证平台**：介绍了 StarLogo、Webots、Swarm、Breve、Player/Stage、SwarmFare、ARGoS/Buzz 七款可免费下载或开源的仿真验证平台，各平台在功能、适用场景和支持系统等方面各具特点 。
5. **研究结论与展望**：全面梳理了机器人集群路径规划技术，包括计算架构、规划方法和仿真平台。未来将拓展至机器人集群运动规划和任务规划领域，为科研和教学提供更科学的指导。



## 学位论文

#### 基于**ROS**的**机器人集群**虚实协同**导航**系统研究与实现

**摘要：**[基于ROS的机器人集群虚实协同导航系统研究与实现 - 中国知网](https://elib.ustb.edu.cn/https/77726476706e69737468656265737421fbf952d2243e635930068cb8/kcms2/article/abstract?v=loqPUsRAn-KNpqjmKwzvHRGSPQ8dqXkXsYCTLoAT1S4hmnY8rFi9bdqdwXgCB4Yf6D6JDGBU75IvOlgPAyPYf6YftrYjEHJi7XPahNfJPG4of2CQyCLeE7F8hgt773sTxnI-By4S0rULxD_A3odRljLJkxoLBlQwhaABZShsOZ_QpQAIDSr_yzTJqmb-Rki47x2xjqyfz28=&uniplatform=NZKPT&language=CHS)

**引用格式：**

[1]林炽杰.基于ROS的机器人集群虚实协同导航系统研究与实现[D].哈尔滨工业大学,2021.DOI:10.27061/d.cnki.ghgdu.2021.003191.

**可用到内容：**

- **在撰写毕业设计论文大纲及正文之前，强烈建议回顾并深入研读该参考文献**
- **第1章：**国内外研究现状 室内机器人导航技术：
  - 总结了室内机器人导航的关键技术和研究进展。 
  - 多机器人路径规划技术：分析了多机器人协同路径规划的现状和挑战，适合用于背景介绍。
- **第2章：**关键技术介绍 **(可以参考这种写作方式)**
  - ROS系统：深入浅出地介绍ROS通信机制（节点、话题、服务），适合初学者了解ROS基础。 
  - SLAM技术：讲解了Gmapping和Cartographer两种SLAM算法，适合用于建图和定位。 
  - 定位算法：介绍蒙特卡罗定位（MCL）和自适应蒙特卡罗定位（AMCL），适合用于机器人定位模块。
- **第5章：**机器人集群虚实结合平台
  - 阐述了如何基于ROS构建多机器人通信框架 
  - 系统架构设计：展示虚实结合平台的总体架构，适合参考集群机器人系统的层次化设计。 
  - 虚实机器人协同：介绍虚实机器人之间的通信和数据融合，适合用于设计协同控制模块。 
  - 实验验证：提供虚实结合平台的实验案例，适合参考算法验证和系统测试。

**大概内容：**

1. 研究背景与现状
   - **研究背景**：机器人技术与人工智能发展迅速，应用广泛。多机器人协同工作优势明显，如系统容错性高、可完成复杂任务，成为研究重点。
   - **研究现状**：室内机器人导航技术涵盖定位、建图和路径规划，相关算法众多，但传统算法存在计算复杂度高、动态性差等问题。多机器人路径规划研究取得一定成果，但动态场景下的交通拥堵和局部冲突死锁问题仍待解决。
2. 关键技术介绍
   - **ROS 机器人操作系统**：对底层硬件封装，提供便捷通信方式、开源工具和先进算法。具有跨平台通信、松散耦合、工具丰富、功能库多样等优势，其核心概念包括节点、消息与话题、服务与参数、ROS 管理器。
   - **室内建图与导航**：SLAM 用于解决位姿与地图未知时的定位和建图问题，介绍了 FastSLAM、Gmapping 和 Cartographer 算法。分层代价地图以栅格形式构建，用于机器人导航。里程计标定可减少导航误差，扩展卡尔曼滤波用于融合里程计和 IMU 数据，提高位姿计算精度。
3. 机器人的定位与导航算法研究
   - **室内定位算法**：蒙特卡罗定位算法利用粒子模拟机器人位姿，自适应蒙特卡罗定位算法在此基础上改进，通过注入随机粒子和动态调整粒子数，解决定位失败无法恢复的问题。
   - **路径规划算法**：介绍 Dijkstra、Best First Search 和 A\*算法，通过仿真实验对比，A*算法结合启发式函数，能在静态地图快速找到近似最优解，被选作全局规划算法。
4. 基于时间窗的多机器人融合路径规划算法
   - **基于时间窗的 A \* 算法**：针对多机器人协同工作场景，提出基于时间窗改进的 A * 算法，为节点分配时间窗，避免路径冲突，修改启发函数考虑多种成本因素，经仿真实验验证有效。
   - **融合路径规划算法**：采用 DWA 算法作为局部规划算法，与 A\*算法融合。A*算法规划全局路径，DWA 算法根据局部信息调整，融合算法减少路径重规划次数，提高任务完成率。
5. 机器人集群虚实结合平台与实验
   - **虚实结合平台**：以 Gazebo 为虚拟仿真平台，构建虚拟机器人仿真模型。实际机器人采用差分驱动小车，基于 ROS 话题通信搭建分布式控制系统。
   - **平台设计与实验**：搭建虚实结合平台，进行虚实结合实验和机器人集群导航实验。结果表明，基于时间窗改进的 A * 算法可提高系统整体性能，但仍存在机器人冲突问题。
6. 研究总结
   - **研究贡献**：提出 A\*与 DWA 融合的路径规划算法；提出基于时间窗改进的 A*算法；搭建虚实结合平台，实现虚实机器人协同工作。
   - **研究不足**：基于时间窗的 A * 算法预估时间存在误差，局部规划器处理冲突能力有待提高，现实与虚拟平台数据存在差异。







#### **集群移动机器人**中的**避障算法**研究

**摘要：**[集群移动机器人中的避障算法研究 - 中国知网](https://elib.ustb.edu.cn/https/77726476706e69737468656265737421fbf952d2243e635930068cb8/kcms2/article/abstract?v=loqPUsRAn-If9cId_Ql7QoJsJkCJRjwueEAxRbocdujloWKr3uTqDHp-YzeRISe9zazMXr7tPGNit4KfAVE4Y9hDLoSXduKGHUbg4tv9BsvxzFJV8O6keZA_vjg3IXGZ9H1GJzPdrGxB79jWA_deE59-FK4Fu0SVmEBDdEhA1tIbIxhnaeWkfc43iVLkisERbJbbSPjJ16A=&uniplatform=NZKPT&language=CHS)

**引用格式：**[1]吴万强.集群移动机器人中的避障算法研究[D].沈阳大学,2022.DOI:10.27692/d.cnki.gsydx.2022.000315.

**可用到内容：**

- 文件的整体结构和写作思路（如绪论、平台设计、算法研究、仿真验证、总结与展望等）
- 国内外研究现状、研究意义（国内外多机器人编队控制和路径规划的研究现状、研究意义进行了详细分析）
- 实验验证方法：对实验验证的描述（如运动轨迹对比、误差曲线分析等）可以作为你进行实物验证的参考。主要是进行了对比实验（人工势场算法和优化后的DWA算法在避障效果上的差异）
- 领航-跟随算法的研究与实现：算法原理（包括如何分配角色（领航者和跟随者）、如何计算相对位置和速度等。）；队形控制（队形控制方法（如三角形、菱形编队）和通信拓扑结构（如邻接矩阵））
- ROS系统搭建、传感器集成等硬件平台设计

**大概内容：**

1. **研究背景及意义**：移动机器人应用广泛，在复杂任务场景下，多移动机器人系统应运而生。多机器人编队控制技术成为研究重点，其中集群避障和路径规划是关键技术，对推动多机器人系统在物流运输等领域的应用具有重要意义。
2. 移动机器人编队平台设计
   - **移动机器人系统设计**：选择 ROS 系统搭建移动机器人平台，介绍 ROS 分布式设计、多语言支持、架构精简、工具包丰富等特点及文件系统层、计算图层、开源社区层组成的架构。
   - **机器人硬件平台设计**：设计以麦克娜姆轮为主体的全向移动智能机器人，包括运动底盘和智能控制器。介绍机器人主控制器树莓派、底层驱动器各模块及基于 ROS 的激光雷达的功能和工作原理。
   - **基于 PID 的运动控制器**：在移动机器人底盘设计中采用 PID 控制系统，通过比例、积分、微分环节对电机转动补偿，实现对机器人位置的准确控制。
   - **卡尔曼滤波器设计**：利用卡尔曼滤波器对机器人传感器数据进行滤波，降低噪声影响，提高数据有效性，为集群控制和避障提供可靠数据。
3. 构建集群编队控制模型
   - **集群编队控制算法研究现状**：分析基于行为法、虚拟结构法、人工势场法、领导跟随法等编队控制算法的原理、优缺点及研究发展趋势。
   - **机器人编队运动学模型**：假设机器人编队组成，设定机器人运行速度和转向速度，通过监测领航者与跟随者的距离和速度，调节跟随者速度和旋转角度，实现编队队形控制，介绍常见编队布局类型。
   - **编队拓扑图论**：使用图论描绘编队通信拓扑结构，介绍图的基本概念、分类，以及邻接矩阵在存储节点边信息中的应用，区分无向图和有向图的邻接矩阵特点。
   - **基于领航跟随的系统模型建立**：将移动机器人编队分为领航者和跟随者，介绍领航者跟随者算法的工作原理，建立协同编队的一阶连续系统模型，给出领航者和跟随者的控制算法公式。
4. 移动机器人避障方法研究
   - **移动机器人避障算法研究现状**：介绍路径规划中全局规划与局部规划融合的策略，分析 Bug 算法、人工势场算法、DWA 算法等常见局部规划算法的原理和优缺点。
   - **基于人工势场算法模型建立**：建立人工势场模型，制定引力函数和斥力函数，通过合力使移动机器人向目标点行驶，介绍模型数学表达式。
   - **基于 DWA 算法的系统模型建立**：DWA 算法通过设计动态速度窗，在局部环境中采样速度、模拟轨迹，利用评价函数选取最优轨迹，介绍算法模型、速度采样和位置更新公式及评价函数组成。
   - **针对 DWA 算法的优化**：提出栅格评价函数，将地图栅格化计算代价值，避免算法陷入局部最优；引入编队完整性评价函数，通过计算机器人位置差值，使集群编队在避障时保持队形。
5. 系统编队仿真
   - **多机器人编队控制仿真**：在 MATLAB 环境下，对领航者跟随者算法进行仿真，设定机器人初始位置、速度等参数，仿真结果表明该算法可有效控制集群编队，使跟随者跟随领航者完成编队运动。
   - **多机器人避障仿真**：设置机器人初始位置和障碍物坐标，对比传统 DWA 算法和优化后 DWA 算法的避障效果，结果显示优化后算法在编队约束性、避障后队形恢复速度和轨迹平滑度上更优。
   - **多机器人编队避障对比仿真**：使用人工势场算法和优化后 DWA 算法进行避障对比实验，结果表明优化后 DWA 算法在避障效果、轨迹平整度和对障碍物及目标点选取的适应性上优于人工势场算法。



## 中文期刊

#### 基于策略融合及Spiking DRL的移动机器人路径规划方法

**摘要：**[基于策略融合及Spiking DRL的移动机器人路径规划方法 - 中国知网](https://elib.ustb.edu.cn/https/77726476706e69737468656265737421fbf952d2243e635930068cb8/kcms2/article/abstract?v=loqPUsRAn-L_hpz20aeMF1oMy-aEktETry7CPRmog9NDQOYkmN3Le6yGhuyL7opD5I2rlVlzeSVD4P4IMABOkwVE5ufYMTEwP4-fe8QJM-7S-ZlydC3vSoE7jIUxn5noXY61hzO6K6gXBJHn3P5jNFq6LyqOgDrdlxUwGKSmW6uukqKgOx1tJ0MEdfv136j8&uniplatform=NZKPT&language=CHS&rp=ZKAI)

**引用格式：**[1]安阳,王秀青,赵明华.基于策略融合及Spiking DRL的移动机器人路径规划方法[J].计算机科学,2024,51(S2):69-79.

**可用到内容：**

**大概内容：**



## 外文期刊（近五年）

### 领航跟随法：

**（研究目的/问题）领导-追随者算法在多机器人系统中的应用：** 领导-追随者形成方法被广泛应用于多机器人系统，具有简单易行的特点。多项研究提出了不同的算法以应对系统中的动态变化，如文献[3]中提出的动态领导-追随者算法，和文献[7]中结合了形成控制机制的创新方法，这些方法易于理解并实际应用。

**（主要发现和结果）领导-跟随算法在多机器人系统中的应用：**领导-跟随算法在多机器人系统中被广泛应用，以实现有效的群体协调。例如，在文献[3]中提出了一种动态的领导-跟随方法，该方法易于理解和实施，能够有效处理个体故障的问题；而文献[7]则提出了一种结合队形控制机制的创新领导-跟随控制方法，增强了多机器人系统的协同能力。

**（研究趋势）多智能体系统中的Leader-follower算法应用** 当前，Leader-follower算法在多智能体系统中的应用越来越广泛。研究者不仅关注单一的机器人运动控制，还探讨了复杂环境下的合作策略。例如，文献[3]提出了一种动态的Leader-follower方法，强调了该方法在多智能体系统内的易于理解与实现；而文献[7]则进一步探讨了这一算法在多机器人系统中的新型控制机制，显示出研究的多样化趋势。

**（实际应用）领导-追随者算法的应用与实现：**多项研究探讨了领导-追随者算法在多机器人系统中的应用，其目的在于增强系统的灵活性和稳定性。例如，文献[3]中提出了一种动态领导-追随者方法，以解决个体故障问题；而文献[7]则提出了一种新颖的领导-追随者控制机制，旨在改善形成控制的有效性。



#### 文献3：A Dynamic Leader–Follower Approach for Line Marching of Swarm Robots

**中文题目：**一种用于群体机器人排队行进的动态 Leader-Follower 方法

[Development and Testing of Unmanned Semi-Submersible Vehicle | Unmanned Systems](https://www.worldscientific.com/doi/10.1142/S2301385023

[500048)

**研究背景：**

现有的精确编队算法大多是基于标签指定的，即每个机器人的期望位置由其标签预先确定。这种算法的缺点是容易受到个体故障的影响，一旦某个机器人出现问题，整个编队可能会被破坏。

**提出的方法：**

为了解决这一问题，作者提出了一种动态领导者-跟随者方法。与传统方法不同，这种方法不再通过标签预先设定每个机器人的期望位置，而是根据机器人标签的相对性以及它们的实时相对位置来动态调整期望位置。

**方法的特点：**

通过不断更新领导者-跟随者链的顺序，该算法能够实现精确的编队行进，并且对机器人故障表现出很强的鲁棒性。即使某个机器人出现故障，也不会对整个编队产生严重的影响。



#### 文献7：Logarithmic Potential Field: A New Leader– Follower Robotic Control Mechanism to Enhance the Execution Speed and Safety Attributes

**中文题目：**对数势场：一种新的领导者 – 跟随者机器人控制机制，以提高执行速度和安全属性

[对数势场：新的领导者 – 提高执行速度和安全性属性的从动机器人控制机制 |IEEE期刊和杂志 |IEEE Xplore --- Logarithmic Potential Field: A New Leader– Follower Robotic Control Mechanism to Enhance the Execution Speed and Safety Attributes | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/10214001)

**研究背景与问题：**

- **主从编队控制策略**：在多机器人系统中，主从编队是一种常见的控制策略。在这种策略下，领头机器人（leader）负责确定整个编队的期望轨迹，而跟随机器人（follower）则通过控制系统来跟踪领头机器人的运动。
- **存在的问题**：传统的主从编队控制策略采用分层控制架构，虽然能够实现基本的编队控制，但在复杂的环境中，这种架构无法有效确保跟随机器人成功避障。为了解决这一问题，虽然有研究提出增加避障层，但这样会增加系统的复杂性，降低计算速度，进而影响实时性能。

**改进方法：**

- **新型控制机制**：本文提出了一种新的主从控制机制，将编队控制和避障功能结合在一起，通过一步实现，避免了增加避障层带来的复杂性和计算延迟。
- **路径规划技术**：新的路径规划技术重点在于提高执行速度和安全性，同时确保生成的路径平滑且路径长度在可接受范围内。

**主要贡献：**

- 新型势场建模方法：开发了一种专为多机器人系统中跟随机器人设计的势场建模方法。该势场模型由三个关键项组成：
  - **高斯项（Gaussian term）**：作为排斥力，表示机器人与环境中每个障碍物之间的高斯距离。当机器人靠近障碍物时，该值较大，随着与障碍物距离的增加，该值呈指数衰减。
  - **欧几里得项（Euclidean term）**：表示机器人与领头机器人之间的欧几里得距离，用于寻找到达领头机器人的最短路径。
  - **对数项（Logarithmic term）**：用于确保跟随机器人的安全性，具体作用在文中未完全展开。
- **粒子群优化（PSO）**：利用粒子群优化算法对势场模型中的三个项进行优化，以生成最优路径。PSO是一种群体智能优化算法，通过模拟粒子群的运动来寻找最优解，具有全局搜索能力强、收敛速度快等优点，适用于复杂的路径规划问题。

**总结：**

这篇论文针对多机器人系统中的主从编队控制问题，提出了一种新的控制机制和路径规划技术，通过创新的势场建模方法和粒子群优化算法，有效提高了系统的执行速度、安全性和路径平滑性，解决了传统方法中存在的避障和实时性问题，为多机器人系统的编队控制提供了新的思路和方法。



#### **文献9：A Leader Follower Algorithm Based Path Navigation Approach for Multiple Autonomous Vehicles**

[A Leader Follower Algorithm Based Path Navigation Approach for Multiple Autonomous Vehicles | Research Square](https://www.researchsquare.com/article/rs-3265935/v1)

**中文标题：**一种基于领导者跟随算法的多辆自动驾驶汽车路径导航方法

**研究背景：**在未知环境中进行多智能体路径导航是一项具有挑战性的任务，需要设计一种基于设备间通信的有效算法，以尽可能减少误差。

**提出的方法：**

- 本文提出了一种基于领导者-跟随者算法的多智能体路径导航方法，该算法分为两部分：
  1. **领导者路径导航**：包括避障机制，用于引导整个系统的路径规划。
  2. **跟随者路径更新**：依赖领导者提供的引导信息，实时更新跟随者的路径。

**实验设计：**

- 在模拟环境中，设置了一个领导者和两个跟随者智能体。
- 每个跟随者智能体在领导者开始后几秒钟启动，以模拟实际场景中的时间延迟。

**实验结果：**

- **旅行时间偏差**：平均偏差为2.82%。
- **路径长度偏差**：平均偏差为31%。
- **成功率**：在不同环境中，该方法的平均成功率为66%。
- **准确率**：研究表明，该技术的平均准确率超过54%。

**结论：**

- 该领导者-跟随者算法在多智能体路径导航中表现出一定的有效性，尽管存在一定的路径长度偏差，但在旅行时间和成功率方面表现较好，适合在未知环境中进行多智能体导航任务。

**分布式算法的实际应用：**文献[9]提出了一种基于设备通信的领导-追随者算法，强调了在实际实施中的低错误设计需求。

**资源受限条件下的有效算法实现：**文献[9]则探讨了基于设备间通信设计的领导-追随者算法，强调了在实践中降低误差的重要性，这为在工业环境中的实施提供了理论支持。

**微控制器的资源受限环境实施：**文献[9]提到了一种基于设备通信的领导-跟随算法，在设计时需要考虑最小化误差，展示了在实际环境中的实施潜力。



### 深度强化学习路径规划：

#### Motion Planning for Mobile Robots—Focusing on Deep Reinforcement Learning: A Systematic Review

**中文标题：**移动机器人的运动规划——聚焦深度强化学习：一项系统综述

[Motion Planning for Mobile Robots—Focusing on Deep Reinforcement Learning: A Systematic Review | IEEE Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9419029)

**研究背景：**

- **移动机器人的贡献**：移动机器人对人类社会的智能化发展做出了显著贡献，它们在很多领域发挥着重要作用，比如物流、工业生产、服务行业等，提高了生产效率、减轻了人类劳动强度，推动了社会的智能化进程。
- **运动规划策略的重要性**：对于移动机器人而言，运动规划策略是至关重要的。它决定了机器人如何在环境中安全、高效地移动，以完成各种任务，如避开障碍物、到达目标位置等。

**研究内容与方法：**

- 研究主题：本论文主要回顾了基于运动规划策略的方法，尤其是那些在非结构化环境中涉及深度强化学习（DRL）的方法。
  - **非结构化环境**：与结构化环境（如工厂车间，有明确的布局和固定的路径）相对，非结构化环境更加复杂、动态且不可预测，例如户外自然环境、灾难现场等。在这种环境下，机器人需要具备更强的自主决策和适应能力，而DRL是一种适合解决此类问题的方法。
  - **深度强化学习（DRL）**：它是一种结合了深度学习和强化学习的机器学习方法。通过让机器人在环境中进行试错学习，根据环境反馈的奖励信号来不断优化自身的决策策略，以实现更好的运动规划效果。
- 对传统DRL方法的分类与调研：论文将传统的DRL方法分为三大类：
  - **基于价值的方法（value-based）**：这类方法主要关注的是评估在不同状态下采取不同动作的价值（即预期回报），通过学习一个价值函数来指导机器人的决策。例如Q-learning算法，它通过不断更新Q值（状态-动作对的价值）来找到最优策略。
  - **基于策略的方法（policy-based）**：与基于价值的方法不同，基于策略的方法直接学习一个策略函数，该函数将状态映射到动作概率分布，通过优化策略函数来提高机器人的性能。例如策略梯度方法，它通过计算策略函数的梯度来更新策略参数。
  - **基于演员-评论家的方法（actor-critic-based）**：这是一种结合了基于价值和基于策略方法的混合方法。其中，“演员”（actor）负责学习策略函数，而“评论家”（critic）负责评估策略的好坏，即学习价值函数。两者相互协作、相互更新，以实现更好的学习效果。
  - 论文对这三类方法的相应理论和应用进行了调研，分析了它们在移动机器人运动规划中的优缺点、适用场景以及实际应用案例等。
- 对新兴DRL方法的调研：除了传统的DRL方法，论文还对近年来新出现的DRL方法进行了调研，重点关注了以下几类方法：
  - **模仿学习（imitation learning）**：这是一种让机器人通过模仿人类或其他机器人的行为来学习运动规划策略的方法。例如，通过收集人类操作机器人的数据，然后让机器人学习这些数据中的模式和规律，从而掌握相应的技能。
  - **元学习（meta-learning）**：元学习的目标是让机器人学会如何更好地学习，即通过学习多个任务来提高机器人在新任务上的学习效率和适应能力。在运动规划领域，元学习可以帮助机器人更快地适应不同的环境和任务要求。
  - **多机器人系统（multi-robot systems）**：在多机器人场景下，运动规划变得更加复杂，因为需要考虑多个机器人之间的协调和合作。涉及DRL的多机器人运动规划方法可以让机器人之间通过学习相互协作，共同完成任务，例如编队飞行、协同搬运等。

**研究意义：**

- **启发潜在研究方向**：通过对上述各类DRL方法在移动机器人运动规划领域应用的调研，论文为未来该领域的研究方向提供了启示。这有助于研究人员更好地了解当前的研究进展、存在的问题以及未来可能的发展趋势，从而为移动机器人运动规划算法的研究和开发提供指导和参考，推动移动机器人技术的进一步发展。



#### A deep reinforcement learning based method for real-time path planning and dynamic obstacle avoidance

**中文标题：**一种基于深度强化学习的实时路径规划和动态避障方法

[一种基于深度强化学习的实时路径规划和动态避障方法 - ScienceDirect](https://www.sciencedirect.com/science/article/abs/pii/S0925231222005367)

**研究背景与意义：**

- **机械手的应用与挑战**：机械手是一种模仿人体手臂动作的自动化装置，具有通用性强、动作灵活、易于控制等优点，被广泛应用于各个领域。然而，机械手的工作场景通常不是自由空间，而是有障碍物的约束空间，且随着应用场景的复杂性增加，工作场景中往往包含移动的障碍物，这对机械手的路径规划提出了更高要求。
- **现有方法的局限性**：大多数现有方法主要针对静态环境中的障碍物，而在动态环境中，由于移动障碍物的存在，机械手的规划任务变得更加困难，需要更适用的策略来完成任务。

**研究方法：**

- **基于SAC的动态避障路径规划方法**：该文提出了一种基于深度强化学习算法软行为者批评者（SAC）的机械手动态避障路径规划方法。SAC算法是一种先进的强化学习算法，能够在复杂环境中进行有效的决策。
- **综合奖励函数设计**：为了使机械手能够有效避开环境中的移动障碍物并实时规划路径，设计了动态避障和目标接近的综合奖励函数。这个奖励函数综合考虑了避障和接近目标两个关键因素，通过合理的奖励机制引导机械手的行为。
- **优先经验重放（PER）的应用**：针对随机抽样导致样本利用率低的问题，采用优先经验重放（PER）来改变样本的权重。PER通过赋予高价值样本更高的权重，提高了采样效率，从而加快了智能体的学习速度，提高了网络的收敛速度和稳定性。

**实验与结果：**

- **模拟实验**：在仿真环境中对该方法进行了测试，并与DDPG、A3C等其他强化学习方法进行了比较。实验结果表明，该方法能够有效避开环境中的移动障碍物，并以较高的成功率完成规划任务。
- **碰撞检测算法**：针对高自由度机械手的两个不规则物体与障碍物碰撞难以检测的问题，设计了一种碰撞检测算法。与现有方法相比，该算法大大减少了计算量，提高了实时性。

**研究贡献与亮点：**

- **应用拓展**：所提出的机械手动态避障路径规划方法，实现了避障规划在随机动态障碍物环境下的应用，拓展了机械手在复杂环境中的应用范围。
- **性能提升**：通过结合优先经验重放（PER），解决了高价值样本利用率低、智能体学习效率低、网络收敛慢等问题，提高了网络收敛速度和稳定性。
- **碰撞检测优化**：针对高自由度机械手的碰撞检测难题，设计了高效的碰撞检测算法，减少了计算量，提高了实时性。
- **控制模块设计**：机械手基于深度强化学习（DRL）的控制模块经过专门设计，具有全面的奖励功能，能够使机械手实时靠近物体并避开移动障碍物，提高了机械手在动态环境中的适应性和灵活性。

总的来说，这段内容详细介绍了基于SAC算法的机械手动态避障路径规划方法的研究背景、方法、实验以及贡献，展示了该方法在动态环境中机械手路径规划问题上的有效性和优势。



#### Deep reinforcement learning based mobile robot navigation: A review

**中文标题：**基于深度强化学习的移动机器人导航综述

[Deep reinforcement learning based mobile robot navigation: A review | TUP Journals & Magazine | IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9409758)

**摘要**：移动机器人的导航是一个基本问题，深度强化学习（DRL）因其强大的表征能力和经验学习能力而受到广泛关注。目前，将DRL应用于移动机器人导航的趋势日益增长。本文首先回顾了DRL方法以及基于DRL的导航框架。接着，我们系统地比较和分析了四种典型应用场景之间的关系和差异，这四种场景分别是局部避障、室内导航、多机器人导航以及社交导航。然后，我们描述了基于DRL的导航的发展历程。最后，我们探讨了有关基于DRL的导航所面临的挑战以及一些可能的解决方案。



### 基于 ROS 的多机器人系统

#### mrgs: A Multi-Robot SLAM Framework for ROS with Efficient Information Sharing

[mrgs: A Multi-Robot SLAM Framework for ROS with Efficient Information Sharing | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-030-45956-7_3)

**中文标题：**mrgs：具有高效信息共享的 ROS 多机器人 SLAM 框架

**1. 探索未知环境的问题描述**

- 探索未知环境是一个特别且可以直观分解的问题。这意味着整个探索任务可以被拆分成更小的部分。
- 机器人团队可以被划分成更小的小组，甚至可以拆分成单个个体，去探索环境中的不同区域。例如在一个大型的未知仓库环境中，一个由多个机器人组成的团队可以分成几组，每组去探索仓库的特定部分，或者有些机器人单独行动去探索一些较为狭窄或者特殊的区域。

**2. 探索过程中的团队协作与问题**

- 在探索过程中，机器人团队可以离散地重新组合，并构建该区域的联合表示。也就是说，这些分散行动的机器人在探索完各自的部分后，可以将它们收集到的信息整合起来，形成对整个区域的完整认知。
- 然而，这种方法也引发了一系列新的问题，例如通信、同步和信息融合。通信问题是机器人之间如何有效地传递信息；同步问题是指机器人在行动和信息更新等方面如何保持一致；信息融合问题则是如何将来自不同机器人、可能包含不同格式和精度的信息整合在一起。例如，机器人A和B在不同的时间点收集了环境信息，它们需要通过有效的通信机制将信息传递给对方，然后确定如何将这些信息在时间上和空间上进行同步，最后将这些信息融合成一个准确的环境表示。

**3. 本研究提出的解决方案**

- 本研究提出了mrgs，这是一个用于多机器人SLAM（同步定位与地图构建）的开源框架。
- 提出的解决方案旨在为任何能够执行单机器人SLAM的系统提供与队友高效通信的能力，并基于与同伴交换的信息构建环境的全局表示。也就是说，这个解决方案的目标是让原本只能单独进行SLAM的机器人系统，能够和其他机器人协同工作，通过相互之间的通信，将各自局部的SLAM结果整合成一个全局的环境表示。
- 该解决方案通过在真实世界数据上进行的实验得到验证，并且研究者分析了其在可扩展性和通信效率方面的性能。例如，随着机器人数量的增加，这个解决方案是否仍然能够有效地工作，以及机器人之间通信时是否存在延迟、数据丢失等问题，这些都是通过实验来分析的。



#### Multi-Robot Cooperative Navigation in Dynamic Environments using Deep Reinforcement Learning in ROS

**中文标题：**在 ROS 中使用深度强化学习在动态环境中进行多机器人协同导航

[Multi-Robot Cooperative Navigation in Dynamic Environments using Deep Reinforcement Learning in ROS | Proceedings of the 2024 2nd International Conference on Frontiers of Intelligent Manufacturing and Automation](https://dl.acm.org/doi/abs/10.1145/3704558.3707121)

**研究背景**

- 在机器人技术快速发展的当下，多机器人协同导航是一个非常关键的研究领域。这种技术的应用范围十分广泛，包括但不限于室内环境监测和物流等领域。然而，在没有预先绘制地图的动态环境中实现自主导航面临着诸多挑战，其中最显著的就是效率问题。

**研究方法**

- 本研究采用了深度强化学习（DRL）技术，并将其应用于机器人操作系统（ROS）框架，以此来实现自主导航以及解决在上述复杂环境中遇到的资源规划难题。具体而言，是将DRL融入到ROS的全局路径规划器中。这样一来，机器人便能够无需依赖事先对环境的了解，实时地学习并执行协同导航策略。

**实验结果**

- 通过模拟实验发现，这种将DRL与ROS相结合的方式，不仅提升了导航效率，还降低了资源消耗。这一结果充分展现了DRL在优化单个机器人以及整个机器人团队导航策略方面的巨大潜力，为多机器人系统在复杂动态环境中的应用提供了新的思路和方法，具有重要的理论和实践意义。





**中文标题：**MultiROS：基于 ROS 的机器人仿真环境，用于并发深度强化学习

[MultiROS：基于 ROS 的机器人仿真环境，用于并行深度强化学习 |IEEE 会议出版物 |IEEE Xplore](https://ieeexplore.ieee.org/abstract/document/9926475)

**研究背景：**

- **自主机器人与深度强化学习**：在追求真正的自主机器人技术的道路上，利用深度强化学习（DRL）技术来解决复杂的机器人任务，已经成为学术界和工业界越来越关注的研究方向。深度强化学习是一种让机器人通过与环境的交互来学习最优行为策略的方法，它能够使机器人在复杂的、动态的环境中自主地做出决策，完成各种复杂的任务。
- **现有的仿真框架**：目前，已经存在许多用于评估机器人上的DRL算法的仿真框架。这些框架通常会提供一些预构建的任务，或者提供工具来创建自定义的环境，以便研究人员能够在虚拟环境中测试和优化他们的算法。这些仿真框架为机器人学习算法的研究提供了重要的支持，使得研究人员能够在不直接操作真实机器人的情况下进行大量的实验和验证。

**现有框架的局限性：**

- **基于ROS的DRL框架**：在众多的仿真框架中，使用基于机器人操作系统（ROS）的DRL框架来进行仿真和在现实世界中的部署，是一种非常受欢迎的方法。ROS是一个用于机器人应用开发的中间件，它提供了硬件抽象、设备驱动、库、工具、代码复用等丰富的功能，使得机器人软件的开发更加高效和便捷。然而，尽管现有的基于ROS的DRL仿真框架（如openai_ros或Gym-gazebo）为创建环境提供了框架，但它们存在一些局限性。
- **不支持矢量化环境和并行模拟**：这些现有的框架不支持使用矢量化环境进行训练，矢量化环境可以同时处理多个环境实例，从而加快训练过程。此外，它们也不支持并行模拟，这使得在测试和评估元学习、多任务学习和迁移学习方法时受到了限制。元学习是指让机器人学习如何学习，以便能够快速适应新的任务；多任务学习是指让机器人同时学习多个任务，提高学习效率；迁移学习是指将机器人在一个任务上学到的知识迁移到另一个相关任务上，以提高学习性能。这些方法在机器人学习领域具有重要的研究价值，但现有的框架无法很好地支持它们的实现。

**MultiROS框架的提出：**

- **框架介绍**：为了解决上述现有框架的局限性，研究者们提出了MultiROS。MultiROS是一个3D机器人仿真框架，它包含了一系列为深度强化学习（DRL）研究预构建的环境。这个框架旨在克服现有框架的限制，为研究人员提供一个更加强大和灵活的工具来进行机器人学习算法的研究。
- **与Gazebo的接口和模块化结构**：MultiROS通过ROS与Gazebo机器人模拟器进行连接。Gazebo是一个广泛使用的机器人模拟器，它能够提供逼真的物理模拟和丰富的传感器模型，使得机器人能够在虚拟环境中进行各种操作和交互。MultiROS提供了一个模块化结构，使得研究人员可以方便地创建基于ROS的强化学习环境。这种模块化的设计使得框架具有很好的可扩展性和灵活性，研究人员可以根据自己的需求添加或修改环境的各个模块，以满足不同的研究目的。
- **支持并行训练和数据访问**：与现有的其他框架不同，MultiROS支持在多个环境中并行进行训练，并且可以同时访问每个模拟的数据。这意味着研究人员可以在多个不同的环境实例中同时训练机器人，大大加快了训练的速度。同时，能够实时获取每个模拟中的数据，为算法的调试和优化提供了便利。
- **与OpenAI Gym的兼容性**：此外，MultiROS使用了流行的OpenAI Gym接口。OpenAI Gym是一个用于开发和比较强化学习算法的工具包，它提供了一套标准化的环境接口，使得不同的强化学习算法可以在相同的环境中进行测试和比较。由于MultiROS采用了OpenAI Gym接口，因此它与大多数使用第三方Python框架的基于OpenAI Gym的强化学习算法兼容。这使得研究人员可以方便地将现有的强化学习算法应用到MultiROS框架中，无需进行大量的代码修改和适配工作，大大提高了研究效率。
